{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "# Import KhayatMiniNN\n",
    "from KhayatMiniNN.neural_network import NeuralNetwork\n",
    "from KhayatMiniNN.trainer import Trainer\n",
    "from KhayatMiniNN.layers import LSTM, GRU, Conv1D, Dense, ReLU, Sigmoid, MaxPooling1D\n",
    "from KhayatMiniNN.layers.base import Layer\n",
    "from KhayatMiniNN.regularization import Dropout\n",
    "from KhayatMiniNN.losses import BinaryCrossEntropy\n",
    "from KhayatMiniNN.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "class Flatten(Layer):\n",
    "    def __init__(self, name=\"Flatten\"):\n",
    "        super().__init__(name)\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        self.input = input_data\n",
    "        batch_size = input_data.shape[0]\n",
    "        return input_data.reshape(batch_size, -1)\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        return output_grad.reshape(self.input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Hybrid\n",
      "Sequence Length: 20\n",
      "Number of Features: 71\n"
     ]
    }
   ],
   "source": [
    "# Load model comparison results\n",
    "model_dir = Path(\"../models\")\n",
    "data_dir = Path(\"../data/processed\")\n",
    "\n",
    "with open(model_dir / \"model_comparison.pkl\", \"rb\") as f:\n",
    "    model_info = pickle.load(f)\n",
    "\n",
    "best_model_name = model_info['best_model']\n",
    "sequence_length = model_info['sequence_length']\n",
    "feature_cols = model_info['feature_cols']\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Sequence Length: {sequence_length}\")\n",
    "print(f\"Number of Features: {len(feature_cols)}\")\n",
    "\n",
    "# Load feature-engineered data\n",
    "val_df = pd.read_csv(data_dir / \"val_features.csv\")\n",
    "test_df = pd.read_csv(data_dir / \"test_features.csv\")\n",
    "\n",
    "print(f\"\\nValidation samples: {len(val_df):,}\")\n",
    "print(f\"Test samples: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recreate Model Architecture and Load Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded LSTM model parameters\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "input_size = len(feature_cols)\n",
    "lstm_hidden = 64\n",
    "gru_hidden = 64\n",
    "conv_filters = 32\n",
    "\n",
    "# Define model architectures (same as training)\n",
    "def build_lstm_model():\n",
    "    \"\"\"Build LSTM model.\"\"\"\n",
    "    model = NeuralNetwork(name=\"LSTM_Stock_Predictor\")\n",
    "    model.add_layer(LSTM(input_size, lstm_hidden, return_sequences=False), name=\"lstm1\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(lstm_hidden, 32), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(Dense(32, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "def build_gru_model():\n",
    "    \"\"\"Build GRU model.\"\"\"\n",
    "    model = NeuralNetwork(name=\"GRU_Stock_Predictor\")\n",
    "    model.add_layer(GRU(input_size, gru_hidden, return_sequences=False), name=\"gru1\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(gru_hidden, 32), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(Dense(32, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "def build_conv1d_model():\n",
    "    \"\"\"Build Conv1D model.\"\"\"\n",
    "    seq_after_pool1 = (sequence_length - 2) // 2 + 1\n",
    "    seq_after_pool2 = (seq_after_pool1 - 2) // 2 + 1\n",
    "    flattened_size = seq_after_pool2 * (conv_filters * 2)\n",
    "    \n",
    "    model = NeuralNetwork(name=\"Conv1D_Stock_Predictor\")\n",
    "    model.add_layer(Conv1D(input_size, conv_filters, kernel_size=3, padding='same'), name=\"conv1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool1\")\n",
    "    model.add_layer(Conv1D(conv_filters, conv_filters*2, kernel_size=3, padding='same'), name=\"conv2\")\n",
    "    model.add_layer(ReLU(), name=\"relu2\")\n",
    "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool2\")\n",
    "    model.add_layer(Flatten(), name=\"flatten\")\n",
    "    model.add_layer(Dense(flattened_size, 64), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu3\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(64, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "def build_hybrid_model():\n",
    "    \"\"\"Build Conv1D + LSTM hybrid model.\"\"\"\n",
    "    model = NeuralNetwork(name=\"Hybrid_ConvLSTM_Stock_Predictor\")\n",
    "    model.add_layer(Conv1D(input_size, conv_filters, kernel_size=3, padding='same'), name=\"conv1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool1\")\n",
    "    model.add_layer(LSTM(conv_filters, lstm_hidden, return_sequences=False), name=\"lstm1\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(lstm_hidden, 32), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu2\")\n",
    "    model.add_layer(Dense(32, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "# Build the best model\n",
    "model_builders = {\n",
    "    'LSTM': build_lstm_model,\n",
    "    'GRU': build_gru_model,\n",
    "    'Conv1D': build_conv1d_model,\n",
    "    'Hybrid': build_hybrid_model\n",
    "}\n",
    "\n",
    "model = model_builders[best_model_name]()\n",
    "loss_fn = BinaryCrossEntropy(from_logits=False)\n",
    "model.set_loss(loss_fn)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "trainer = Trainer(model, optimizer, loss_fn)\n",
    "\n",
    "# Load best model parameters\n",
    "with open(model_dir / \"best_model_params.pkl\", \"rb\") as f:\n",
    "    best_params = pickle.load(f)\n",
    "\n",
    "model.set_params(best_params)\n",
    "print(f\"‚úì Loaded {best_model_name} model parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sequences for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Data or model info not loaded. Loading now...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Memory-optimized sequence creation (same approach as training notebook)\n",
    "# Limit dataset size to prevent memory/disk issues\n",
    "MAX_SAMPLES_VAL = 50000   # Limit validation samples (‚âà0.65 GB)\n",
    "MAX_SAMPLES_TEST = 100000  # Limit test samples (‚âà1.3 GB)\n",
    "SAMPLE_RATE = 1.0  # Sample rate for sequences (1.0 = all, 0.1 = 10% of sequences)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Ensure data and model info are loaded (safety check)\n",
    "try:\n",
    "    _ = val_df\n",
    "    _ = test_df\n",
    "    _ = feature_cols\n",
    "    _ = sequence_length\n",
    "    print(\"‚úì Data and model info already loaded\")\n",
    "except NameError:\n",
    "    print(\"‚ö† Data or model info not loaded. Loading now...\")\n",
    "    model_dir = Path(\"../models\")\n",
    "    data_dir = Path(\"../data/processed\")\n",
    "    \n",
    "    # Load model info\n",
    "    with open(model_dir / \"model_comparison.pkl\", \"rb\") as f:\n",
    "        model_info = pickle.load(f)\n",
    "    \n",
    "    best_model_name = model_info['best_model']\n",
    "    sequence_length = model_info['sequence_length']\n",
    "    feature_cols = model_info['feature_cols']\n",
    "    \n",
    "    # Load data\n",
    "    val_df = pd.read_csv(data_dir / \"val_features.csv\")\n",
    "    test_df = pd.read_csv(data_dir / \"test_features.csv\")\n",
    "    \n",
    "    print(f\"‚úì Loaded model info: {best_model_name}, seq_len={sequence_length}, features={len(feature_cols)}\")\n",
    "    print(f\"‚úì Loaded validation samples: {len(val_df):,}\")\n",
    "    print(f\"‚úì Loaded test samples: {len(test_df):,}\")\n",
    "\n",
    "def create_sequences_in_memory_with_metadata(df, feature_cols, sequence_length, target_col='target', \n",
    "                                             max_samples=None, sample_rate=1.0):\n",
    "    \"\"\"\n",
    "    Create sequences in memory grouped by ticker with metadata (ticker, date).\n",
    "    Memory-optimized version that pre-allocates arrays and uses float32.\n",
    "    \"\"\"\n",
    "    if max_samples is None:\n",
    "        raise ValueError(\"max_samples must be set to avoid memory errors.\")\n",
    "    \n",
    "    # Pre-allocate arrays for better memory management (float32 saves 50% memory vs float64)\n",
    "    X = np.zeros((max_samples, sequence_length, len(feature_cols)), dtype=np.float32)\n",
    "    y = np.zeros(max_samples, dtype=np.float32)\n",
    "    ticker_list = []\n",
    "    date_list = []\n",
    "    current_idx = 0\n",
    "    \n",
    "    print(\"  Creating sequences per ticker...\")\n",
    "    tickers = df['Ticker'].unique()\n",
    "    \n",
    "    for ticker_idx, ticker in enumerate(tickers):\n",
    "        if current_idx >= max_samples:\n",
    "            break\n",
    "            \n",
    "        ticker_data = df[df['Ticker'] == ticker].sort_values('Date')\n",
    "        features = ticker_data[feature_cols].values.astype(np.float32)\n",
    "        targets = ticker_data[target_col].values.astype(np.float32)\n",
    "        dates = ticker_data['Date'].values\n",
    "        \n",
    "        if len(features) < sequence_length:\n",
    "            continue\n",
    "        \n",
    "        # Create sliding window sequences for this ticker\n",
    "        num_sequences = len(features) - sequence_length + 1\n",
    "        \n",
    "        # Apply sampling if needed\n",
    "        if sample_rate < 1.0:\n",
    "            num_sequences = int(num_sequences * sample_rate)\n",
    "            indices = np.random.choice(len(features) - sequence_length + 1, \n",
    "                                      size=num_sequences, replace=False)\n",
    "            indices = np.sort(indices)\n",
    "        else:\n",
    "            indices = np.arange(len(features) - sequence_length + 1)\n",
    "        \n",
    "        for i in indices:\n",
    "            if current_idx >= max_samples:\n",
    "                break\n",
    "            X[current_idx] = features[i:i+sequence_length]\n",
    "            y[current_idx] = targets[i+sequence_length-1]\n",
    "            ticker_list.append(ticker)\n",
    "            date_list.append(dates[i+sequence_length-1])\n",
    "            current_idx += 1\n",
    "        \n",
    "        if (ticker_idx + 1) % 100 == 0:\n",
    "            print(f\"  Processed {ticker_idx + 1}/{len(tickers)} tickers, {current_idx:,} sequences...\", end='\\r')\n",
    "    \n",
    "    print(f\"  Completed: {current_idx:,} sequences created\")\n",
    "    \n",
    "    # Trim to actual size\n",
    "    if current_idx < max_samples:\n",
    "        X = X[:current_idx]\n",
    "        y = y[:current_idx]\n",
    "    \n",
    "    return X, y, np.array(ticker_list), np.array(date_list)\n",
    "\n",
    "# Create sequences\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Creating Sequences for Evaluation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nUsing MAX_SAMPLES_VAL = {MAX_SAMPLES_VAL:,} (‚âà{MAX_SAMPLES_VAL * sequence_length * len(feature_cols) * 4 / 1024**3:.2f} GB)\")\n",
    "print(f\"Using MAX_SAMPLES_TEST = {MAX_SAMPLES_TEST:,} (‚âà{MAX_SAMPLES_TEST * sequence_length * len(feature_cols) * 4 / 1024**3:.2f} GB)\")\n",
    "\n",
    "print(\"\\nCreating sequences for validation set...\")\n",
    "X_val, y_val, tickers_val, dates_val = create_sequences_in_memory_with_metadata(\n",
    "    val_df, feature_cols, sequence_length,\n",
    "    max_samples=MAX_SAMPLES_VAL, sample_rate=SAMPLE_RATE\n",
    ")\n",
    "print(f\"‚úì Val sequences: {X_val.shape}\")\n",
    "print(f\"Memory usage: {X_val.nbytes / 1024**3:.2f} GB (float32)\")\n",
    "\n",
    "print(\"\\nCreating sequences for test set...\")\n",
    "X_test, y_test, tickers_test, dates_test = create_sequences_in_memory_with_metadata(\n",
    "    test_df, feature_cols, sequence_length,\n",
    "    max_samples=MAX_SAMPLES_TEST, sample_rate=SAMPLE_RATE\n",
    ")\n",
    "print(f\"‚úì Test sequences: {X_test.shape}\")\n",
    "print(f\"Memory usage: {X_test.nbytes / 1024**3:.2f} GB (float32)\")\n",
    "\n",
    "# Free up memory by deleting dataframes\n",
    "del val_df, test_df\n",
    "import gc\n",
    "gc.collect()\n",
    "print(\"\\n‚úì Freed memory from dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Model Comparison (Using Training Methods)\n",
    "\n",
    "Compare all models on validation and test sets using the same methods as in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Model Comparison on Validation and Test Sets\n",
      "============================================================\n",
      "\n",
      "Training Results (from training notebook):\n",
      "Model  Train Val Loss  Train Val Accuracy  Train Accuracy\n",
      "  GRU        0.681346               54.68          57.237\n",
      " LSTM        0.684898               58.02          57.912\n",
      "\n",
      "Evaluating all models...\n",
      "  Evaluating LSTM...   ‚ö† Error evaluating LSTM: shapes (50000,64) and (48,48) not aligned: 64 (dim 1) != 48 (dim 0)\n",
      "‚úó (no saved parameters)\n",
      "  Evaluating GRU... ‚úó (no saved parameters)\n",
      "  Evaluating Conv1D... ‚úó (no saved parameters)\n",
      "  Evaluating Hybrid... ‚úó (no saved parameters)\n",
      "\n",
      "‚ö† Only best model parameters are available. Cannot compare all models.\n",
      "   To compare all models, you need to save parameters for all models during training.\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison - Using methods from training notebook\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Comparison on Validation and Test Sets\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load training comparison results if available\n",
    "training_comparison = None\n",
    "if 'models_results' in model_info:\n",
    "    training_comparison = model_info['models_results']\n",
    "    print(\"\\nTraining Results (from training notebook):\")\n",
    "    training_df = pd.DataFrame([\n",
    "        {\n",
    "            'Model': name,\n",
    "            'Train Val Loss': results['val_loss'],\n",
    "            'Train Val Accuracy': results['val_accuracy'],\n",
    "            'Train Accuracy': results['train_accuracy']\n",
    "        }\n",
    "        for name, results in training_comparison.items()\n",
    "    ]).sort_values('Train Val Loss')\n",
    "    print(training_df.to_string(index=False))\n",
    "\n",
    "# Function to evaluate a model (same approach as training notebook)\n",
    "def evaluate_model(model_name, model_builder, X_val, y_val, X_test, y_test):\n",
    "    \"\"\"Evaluate a model on validation and test sets.\"\"\"\n",
    "    try:\n",
    "        # Build model\n",
    "        model = model_builder()\n",
    "        loss_fn = BinaryCrossEntropy(from_logits=False)\n",
    "        model.set_loss(loss_fn)\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "        trainer = Trainer(model, optimizer, loss_fn)\n",
    "        \n",
    "        # Try to load parameters if available\n",
    "        params_file = model_dir / f\"{model_name.lower()}_params.pkl\"\n",
    "        if params_file.exists():\n",
    "            with open(params_file, \"rb\") as f:\n",
    "                params = pickle.load(f)\n",
    "            model.set_params(params)\n",
    "            has_params = True\n",
    "        else:\n",
    "            # Use best model params if this is the best model\n",
    "            if model_name == best_model_name:\n",
    "                model.set_params(best_params)\n",
    "                has_params = True\n",
    "            else:\n",
    "                has_params = False\n",
    "                return None\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy = trainer.evaluate(X_val, y_val.reshape(-1, 1))\n",
    "        y_val_pred = trainer.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int).flatten()\n",
    "        val_precision = precision_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "        val_recall = recall_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "        val_f1 = f1_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_loss, test_accuracy = trainer.evaluate(X_test, y_test.reshape(-1, 1))\n",
    "        y_test_pred = trainer.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int).flatten()\n",
    "        test_precision = precision_score(y_test, y_test_pred_binary, zero_division=0)\n",
    "        test_recall = recall_score(y_test, y_test_pred_binary, zero_division=0)\n",
    "        test_f1 = f1_score(y_test, y_test_pred_binary, zero_division=0)\n",
    "        \n",
    "        return {\n",
    "            'Model': model_name,\n",
    "            'Val Loss': val_loss,\n",
    "            'Val Accuracy': val_accuracy,\n",
    "            'Val Precision': val_precision,\n",
    "            'Val Recall': val_recall,\n",
    "            'Val F1': val_f1,\n",
    "            'Test Loss': test_loss,\n",
    "            'Test Accuracy': test_accuracy,\n",
    "            'Test Precision': test_precision,\n",
    "            'Test Recall': test_recall,\n",
    "            'Test F1': test_f1,\n",
    "            'Has Params': has_params\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ö† Error evaluating {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Evaluate all models\n",
    "print(\"\\nEvaluating all models...\")\n",
    "evaluation_results = []\n",
    "\n",
    "for model_name in ['LSTM', 'GRU', 'Conv1D', 'Hybrid']:\n",
    "    print(f\"  Evaluating {model_name}...\", end=' ')\n",
    "    result = evaluate_model(model_name, model_builders[model_name], X_val, y_val, X_test, y_test)\n",
    "    if result:\n",
    "        evaluation_results.append(result)\n",
    "        print(\"‚úì\")\n",
    "    else:\n",
    "        print(\"‚úó (no saved parameters)\")\n",
    "\n",
    "# Create comparison DataFrame (same format as training notebook)\n",
    "if evaluation_results:\n",
    "    comparison_df = pd.DataFrame(evaluation_results).sort_values('Val Loss')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Model Comparison - Evaluation Results\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nValidation Set Performance:\")\n",
    "    val_comparison = comparison_df[['Model', 'Val Loss', 'Val Accuracy', 'Val Precision', 'Val Recall', 'Val F1']].copy()\n",
    "    val_comparison.columns = ['Model', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    print(val_comparison.to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\\nTest Set Performance:\")\n",
    "    test_comparison = comparison_df[['Model', 'Test Loss', 'Test Accuracy', 'Test Precision', 'Test Recall', 'Test F1']].copy()\n",
    "    test_comparison.columns = ['Model', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1']\n",
    "    print(test_comparison.to_string(index=False))\n",
    "    \n",
    "    # Best model based on validation loss\n",
    "    best_eval_model = comparison_df.iloc[0]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üèÜ Best Model (by Val Loss): {best_eval_model['Model']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Validation Loss: {best_eval_model['Val Loss']:.4f}\")\n",
    "    print(f\"  Validation Accuracy: {best_eval_model['Val Accuracy']:.2f}%\")\n",
    "    print(f\"  Test Loss: {best_eval_model['Test Loss']:.4f}\")\n",
    "    print(f\"  Test Accuracy: {best_eval_model['Test Accuracy']:.2f}%\")\n",
    "    \n",
    "    # Compare with training results\n",
    "    if training_comparison:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Comparison: Training vs Evaluation\")\n",
    "        print(f\"{'='*60}\")\n",
    "        combined_comparison = []\n",
    "        for model_name in comparison_df['Model'].values:\n",
    "            if model_name in training_comparison:\n",
    "                train_result = training_comparison[model_name]\n",
    "                eval_result = comparison_df[comparison_df['Model'] == model_name].iloc[0]\n",
    "                combined_comparison.append({\n",
    "                    'Model': model_name,\n",
    "                    'Train Val Loss': train_result['val_loss'],\n",
    "                    'Eval Val Loss': eval_result['Val Loss'],\n",
    "                    'Train Val Acc': train_result['val_accuracy'],\n",
    "                    'Eval Val Acc': eval_result['Val Accuracy'],\n",
    "                    'Diff Loss': eval_result['Val Loss'] - train_result['val_loss'],\n",
    "                    'Diff Acc': eval_result['Val Accuracy'] - train_result['val_accuracy']\n",
    "                })\n",
    "        \n",
    "        if combined_comparison:\n",
    "            combined_df = pd.DataFrame(combined_comparison)\n",
    "            print(combined_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\n‚ö† Only best model parameters are available. Cannot compare all models.\")\n",
    "    print(\"   To compare all models, you need to save parameters for all models during training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Saved training comparison plots to ../models/model_comparison_training.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize model comparison\n",
    "if evaluation_results and len(evaluation_results) > 1:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    comparison_df_viz = pd.DataFrame(evaluation_results).sort_values('Val Loss')\n",
    "    \n",
    "    # 1. Validation Loss Comparison\n",
    "    ax1 = axes[0, 0]\n",
    "    bars1 = ax1.barh(comparison_df_viz['Model'], comparison_df_viz['Val Loss'], \n",
    "                     color=['green' if m == best_model_name else 'steelblue' for m in comparison_df_viz['Model']])\n",
    "    ax1.set_xlabel('Validation Loss')\n",
    "    ax1.set_title('Model Comparison - Validation Loss')\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (idx, row) in enumerate(comparison_df_viz.iterrows()):\n",
    "        ax1.text(row['Val Loss'], i, f\"  {row['Val Loss']:.4f}\", \n",
    "                va='center', fontweight='bold' if row['Model'] == best_model_name else 'normal')\n",
    "    \n",
    "    # 2. Validation Accuracy Comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    bars2 = ax2.barh(comparison_df_viz['Model'], comparison_df_viz['Val Accuracy'],\n",
    "                     color=['green' if m == best_model_name else 'steelblue' for m in comparison_df_viz['Model']])\n",
    "    ax2.set_xlabel('Validation Accuracy (%)')\n",
    "    ax2.set_title('Model Comparison - Validation Accuracy')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (idx, row) in enumerate(comparison_df_viz.iterrows()):\n",
    "        ax2.text(row['Val Accuracy'], i, f\"  {row['Val Accuracy']:.2f}%\", \n",
    "                va='center', fontweight='bold' if row['Model'] == best_model_name else 'normal')\n",
    "    \n",
    "    # 3. Test Loss Comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    bars3 = ax3.barh(comparison_df_viz['Model'], comparison_df_viz['Test Loss'],\n",
    "                     color=['green' if m == best_model_name else 'steelblue' for m in comparison_df_viz['Model']])\n",
    "    ax3.set_xlabel('Test Loss')\n",
    "    ax3.set_title('Model Comparison - Test Loss')\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (idx, row) in enumerate(comparison_df_viz.iterrows()):\n",
    "        ax3.text(row['Test Loss'], i, f\"  {row['Test Loss']:.4f}\", \n",
    "                va='center', fontweight='bold' if row['Model'] == best_model_name else 'normal')\n",
    "    \n",
    "    # 4. Test Accuracy Comparison\n",
    "    ax4 = axes[1, 1]\n",
    "    bars4 = ax4.barh(comparison_df_viz['Model'], comparison_df_viz['Test Accuracy'],\n",
    "                     color=['green' if m == best_model_name else 'steelblue' for m in comparison_df_viz['Model']])\n",
    "    ax4.set_xlabel('Test Accuracy (%)')\n",
    "    ax4.set_title('Model Comparison - Test Accuracy')\n",
    "    ax4.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (idx, row) in enumerate(comparison_df_viz.iterrows()):\n",
    "        ax4.text(row['Test Accuracy'], i, f\"  {row['Test Accuracy']:.2f}%\", \n",
    "                va='center', fontweight='bold' if row['Model'] == best_model_name else 'normal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../models/model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n‚úì Saved model comparison plots to ../models/model_comparison.png\")\n",
    "    plt.show()\n",
    "    \n",
    "elif training_comparison:\n",
    "    # If we only have training results, visualize those\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    training_df_viz = pd.DataFrame([\n",
    "        {\n",
    "            'Model': name,\n",
    "            'Val Loss': results['val_loss'],\n",
    "            'Val Accuracy': results['val_accuracy']\n",
    "        }\n",
    "        for name, results in training_comparison.items()\n",
    "    ]).sort_values('Val Loss')\n",
    "    \n",
    "    # Training Validation Loss\n",
    "    ax1 = axes[0]\n",
    "    bars1 = ax1.barh(training_df_viz['Model'], training_df_viz['Val Loss'],\n",
    "                     color=['green' if m == best_model_name else 'steelblue' for m in training_df_viz['Model']])\n",
    "    ax1.set_xlabel('Validation Loss')\n",
    "    ax1.set_title('Model Comparison - Training Validation Loss')\n",
    "    ax1.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (idx, row) in enumerate(training_df_viz.iterrows()):\n",
    "        ax1.text(row['Val Loss'], i, f\"  {row['Val Loss']:.4f}\", \n",
    "                va='center', fontweight='bold' if row['Model'] == best_model_name else 'normal')\n",
    "    \n",
    "    # Training Validation Accuracy\n",
    "    ax2 = axes[1]\n",
    "    bars2 = ax2.barh(training_df_viz['Model'], training_df_viz['Val Accuracy'],\n",
    "                     color=['green' if m == best_model_name else 'steelblue' for m in training_df_viz['Model']])\n",
    "    ax2.set_xlabel('Validation Accuracy (%)')\n",
    "    ax2.set_title('Model Comparison - Training Validation Accuracy')\n",
    "    ax2.grid(True, alpha=0.3, axis='x')\n",
    "    for i, (idx, row) in enumerate(training_df_viz.iterrows()):\n",
    "        ax2.text(row['Val Accuracy'], i, f\"  {row['Val Accuracy']:.2f}%\", \n",
    "                va='center', fontweight='bold' if row['Model'] == best_model_name else 'normal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../models/model_comparison_training.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\n‚úì Saved training comparison plots to ../models/model_comparison_training.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. Detailed Evaluation for Each Model\n",
    "\n",
    "Detailed metrics (precision, recall, F1, confusion matrix) for each model, similar to training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö† Only best model parameters available. Showing detailed evaluation for best model only.\n",
      "   (See sections 4-5 for detailed evaluation of best model)\n"
     ]
    }
   ],
   "source": [
    "# Detailed evaluation for each model (same format as training notebook)\n",
    "if evaluation_results:\n",
    "    for model_result in comparison_df.itertuples():\n",
    "        model_name = model_result.Model\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Detailed Evaluation: {model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Rebuild and load model for detailed evaluation\n",
    "        model = model_builders[model_name]()\n",
    "        loss_fn = BinaryCrossEntropy(from_logits=False)\n",
    "        model.set_loss(loss_fn)\n",
    "        optimizer = Adam(learning_rate=0.001)\n",
    "        trainer = Trainer(model, optimizer, loss_fn)\n",
    "        \n",
    "        # Load parameters\n",
    "        params_file = model_dir / f\"{model_name.lower()}_params.pkl\"\n",
    "        if params_file.exists():\n",
    "            with open(params_file, \"rb\") as f:\n",
    "                params = pickle.load(f)\n",
    "        else:\n",
    "            params = best_params  # Use best model params if this is the best model\n",
    "        \n",
    "        model.set_params(params)\n",
    "        \n",
    "        # Validation set detailed metrics\n",
    "        print(f\"\\nValidation Set Metrics:\")\n",
    "        y_val_pred = trainer.predict(X_val)\n",
    "        y_val_pred_binary = (y_val_pred > 0.5).astype(int).flatten()\n",
    "        \n",
    "        val_precision = precision_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "        val_recall = recall_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "        val_f1 = f1_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "        \n",
    "        print(f\"  Precision: {val_precision:.4f}\")\n",
    "        print(f\"  Recall: {val_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {val_f1:.4f}\")\n",
    "        \n",
    "        cm_val_detailed = confusion_matrix(y_val, y_val_pred_binary)\n",
    "        print(f\"\\n  Confusion Matrix:\")\n",
    "        print(f\"                Predicted\")\n",
    "        print(f\"              ‚Üì (0)   ‚Üë (1)\")\n",
    "        print(f\"Actual ‚Üì (0)  {cm_val_detailed[0,0]:6d}  {cm_val_detailed[0,1]:6d}\")\n",
    "        print(f\"       ‚Üë (1)  {cm_val_detailed[1,0]:6d}  {cm_val_detailed[1,1]:6d}\")\n",
    "        \n",
    "        # Test set detailed metrics\n",
    "        print(f\"\\nTest Set Metrics:\")\n",
    "        y_test_pred = trainer.predict(X_test)\n",
    "        y_test_pred_binary = (y_test_pred > 0.5).astype(int).flatten()\n",
    "        \n",
    "        test_precision = precision_score(y_test, y_test_pred_binary, zero_division=0)\n",
    "        test_recall = recall_score(y_test, y_test_pred_binary, zero_division=0)\n",
    "        test_f1 = f1_score(y_test, y_test_pred_binary, zero_division=0)\n",
    "        \n",
    "        print(f\"  Precision: {test_precision:.4f}\")\n",
    "        print(f\"  Recall: {test_recall:.4f}\")\n",
    "        print(f\"  F1-Score: {test_f1:.4f}\")\n",
    "        \n",
    "        cm_test_detailed = confusion_matrix(y_test, y_test_pred_binary)\n",
    "        print(f\"\\n  Confusion Matrix:\")\n",
    "        print(f\"                Predicted\")\n",
    "        print(f\"              ‚Üì (0)   ‚Üë (1)\")\n",
    "        print(f\"Actual ‚Üì (0)  {cm_test_detailed[0,0]:6d}  {cm_test_detailed[0,1]:6d}\")\n",
    "        print(f\"       ‚Üë (1)  {cm_test_detailed[1,0]:6d}  {cm_test_detailed[1,1]:6d}\")\n",
    "        \n",
    "        print(f\"\\n  Classification Report (Validation):\")\n",
    "        print(classification_report(y_val, y_val_pred_binary, target_names=['‚Üì Lower', '‚Üë Higher']))\n",
    "        \n",
    "        print(f\"\\n  Classification Report (Test):\")\n",
    "        print(classification_report(y_test, y_test_pred_binary, target_names=['‚Üì Lower', '‚Üë Higher']))\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ö† Only best model parameters available. Showing detailed evaluation for best model only.\")\n",
    "    print(\"   (See sections 4-5 for detailed evaluation of best model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Validation Set Evaluation\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (50000,64) and (48,48) not aligned: 64 (dim 1) != 48 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Set Evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/trainer.py:124\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, X_test, y_test)\u001b[0m\n\u001b[1;32m    121\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_device(y_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_manager)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39m_set_training(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 124\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mcompute_loss(predictions, y_test)\n\u001b[1;32m    126\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mcompute_accuracy(predictions, y_test)\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/neural_network.py:39\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m input_data\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m---> 39\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/layers/lstm.py:110\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    105\u001b[0m x_t \u001b[38;5;241m=\u001b[39m input_data[:, t, :]  \u001b[38;5;66;03m# (batch_size, input_size)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Forget gate\u001b[39;00m\n\u001b[1;32m    108\u001b[0m f_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(x_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW_f\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mU_f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_f\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Input gate\u001b[39;00m\n\u001b[1;32m    115\u001b[0m i_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(x_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW_i\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU_i\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_i\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    119\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (50000,64) and (48,48) not aligned: 64 (dim 1) != 48 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"=\"*60)\n",
    "print(\"Validation Set Evaluation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "val_loss, val_accuracy = trainer.evaluate(X_val, y_val.reshape(-1, 1))\n",
    "print(f\"\\nLoss: {val_loss:.4f}\")\n",
    "print(f\"Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred = trainer.predict(X_val)\n",
    "y_val_pred_proba = y_val_pred.flatten()\n",
    "y_val_pred_binary = (y_val_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "recall = recall_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "f1 = f1_score(y_val, y_val_pred_binary, zero_division=0)\n",
    "\n",
    "try:\n",
    "    auc = roc_auc_score(y_val, y_val_pred_proba)\n",
    "    print(f\"AUC-ROC: {auc:.4f}\")\n",
    "except:\n",
    "    auc = None\n",
    "    print(\"AUC-ROC: Could not calculate (possibly only one class)\")\n",
    "\n",
    "print(f\"\\nPrecision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_val_pred_binary)\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              ‚Üì (0)   ‚Üë (1)\")\n",
    "print(f\"Actual ‚Üì (0)  {cm_val[0,0]:6d}  {cm_val[0,1]:6d}\")\n",
    "print(f\"       ‚Üë (1)  {cm_val[1,0]:6d}  {cm_val[1,1]:6d}\")\n",
    "\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_binary, target_names=['‚Üì Lower', '‚Üë Higher']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Threshold Optimization\n",
    "\n",
    "Find optimal decision threshold to improve performance on imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Threshold Optimization\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (50000,64) and (48,48) not aligned: 64 (dim 1) != 48 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get validation predictions (probabilities)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m y_val_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Method 1: Find threshold that maximizes F1-score\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMethod 1: Maximizing F1-Score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/trainer.py:135\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/neural_network.py:50\u001b[0m, in \u001b[0;36mNeuralNetwork.predict\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_training(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 50\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_training(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/neural_network.py:39\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m input_data\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m---> 39\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/layers/lstm.py:110\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    105\u001b[0m x_t \u001b[38;5;241m=\u001b[39m input_data[:, t, :]  \u001b[38;5;66;03m# (batch_size, input_size)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Forget gate\u001b[39;00m\n\u001b[1;32m    108\u001b[0m f_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(x_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW_f\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mU_f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_f\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Input gate\u001b[39;00m\n\u001b[1;32m    115\u001b[0m i_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(x_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW_i\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU_i\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_i\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    119\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (50000,64) and (48,48) not aligned: 64 (dim 1) != 48 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Threshold Optimization - Find optimal threshold for imbalanced data\n",
    "print(\"=\"*60)\n",
    "print(\"Threshold Optimization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get validation predictions (probabilities)\n",
    "y_val_pred_proba = trainer.predict(X_val).flatten()\n",
    "\n",
    "# Method 1: Find threshold that maximizes F1-score\n",
    "print(\"\\nMethod 1: Maximizing F1-Score\")\n",
    "f1_scores = []\n",
    "thresholds_f1 = np.linspace(0.1, 0.9, 81)  # Test thresholds from 0.1 to 0.9\n",
    "\n",
    "for threshold in thresholds_f1:\n",
    "    y_pred_thresh = (y_val_pred_proba >= threshold).astype(int)\n",
    "    f1 = f1_score(y_val, y_pred_thresh, zero_division=0)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "optimal_idx_f1 = np.argmax(f1_scores)\n",
    "optimal_threshold_f1 = thresholds_f1[optimal_idx_f1]\n",
    "optimal_f1 = f1_scores[optimal_idx_f1]\n",
    "\n",
    "print(f\"  Optimal Threshold (F1): {optimal_threshold_f1:.4f}\")\n",
    "print(f\"  F1-Score at optimal threshold: {optimal_f1:.4f}\")\n",
    "\n",
    "# Method 2: Find threshold that maximizes Youden's J statistic (TPR - FPR)\n",
    "print(\"\\nMethod 2: Maximizing Youden's J (TPR - FPR)\")\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_val, y_val_pred_proba)\n",
    "youden_j = tpr - fpr\n",
    "optimal_idx_j = np.argmax(youden_j)\n",
    "optimal_threshold_j = thresholds_roc[optimal_idx_j]\n",
    "optimal_j = youden_j[optimal_idx_j]\n",
    "\n",
    "print(f\"  Optimal Threshold (Youden's J): {optimal_threshold_j:.4f}\")\n",
    "print(f\"  Youden's J at optimal threshold: {optimal_j:.4f}\")\n",
    "\n",
    "# Method 3: Find threshold that balances precision and recall (closest to (1,1) on PR curve)\n",
    "print(\"\\nMethod 3: Balancing Precision and Recall\")\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_val, y_val_pred_proba)\n",
    "# Find threshold closest to precision=1, recall=1\n",
    "f1_scores_pr = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "optimal_idx_pr = np.argmax(f1_scores_pr)\n",
    "optimal_threshold_pr = thresholds_pr[optimal_idx_pr] if optimal_idx_pr < len(thresholds_pr) else 0.5\n",
    "optimal_f1_pr = f1_scores_pr[optimal_idx_pr]\n",
    "\n",
    "print(f\"  Optimal Threshold (PR Curve): {optimal_threshold_pr:.4f}\")\n",
    "print(f\"  F1-Score at optimal threshold: {optimal_f1_pr:.4f}\")\n",
    "\n",
    "# Compare all methods\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Comparison of Threshold Selection Methods\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "thresholds_to_test = {\n",
    "    'Default (0.5)': 0.5,\n",
    "    'F1-Maximized': optimal_threshold_f1,\n",
    "    'Youden\\'s J': optimal_threshold_j,\n",
    "    'PR-Curve': optimal_threshold_pr\n",
    "}\n",
    "\n",
    "threshold_results = []\n",
    "for method_name, threshold in thresholds_to_test.items():\n",
    "    y_pred_thresh = (y_val_pred_proba >= threshold).astype(int)\n",
    "    acc = accuracy_score(y_val, y_pred_thresh)\n",
    "    prec = precision_score(y_val, y_pred_thresh, zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred_thresh, zero_division=0)\n",
    "    f1 = f1_score(y_val, y_pred_thresh, zero_division=0)\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'Method': method_name,\n",
    "        'Threshold': threshold,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "threshold_comparison_df = pd.DataFrame(threshold_results)\n",
    "print(\"\\n\" + threshold_comparison_df.to_string(index=False))\n",
    "\n",
    "# Select best threshold (prioritize F1-score for imbalanced data)\n",
    "best_method = threshold_comparison_df.loc[threshold_comparison_df['F1-Score'].idxmax(), 'Method']\n",
    "optimal_threshold = thresholds_to_test[best_method]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úì Selected Optimal Threshold: {optimal_threshold:.4f} ({best_method})\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Visualize threshold selection\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. F1-Score vs Threshold\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(thresholds_f1, f1_scores, 'b-', linewidth=2, label='F1-Score')\n",
    "ax1.axvline(optimal_threshold_f1, color='r', linestyle='--', label=f'Optimal: {optimal_threshold_f1:.3f}')\n",
    "ax1.axvline(0.5, color='g', linestyle='--', alpha=0.5, label='Default: 0.5')\n",
    "ax1.set_xlabel('Threshold')\n",
    "ax1.set_ylabel('F1-Score')\n",
    "ax1.set_title('F1-Score vs Threshold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. ROC Curve with optimal threshold\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(fpr, tpr, 'b-', linewidth=2, label=f'ROC Curve (AUC = {roc_auc_score(y_val, y_val_pred_proba):.3f})')\n",
    "ax2.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "# Mark optimal threshold point\n",
    "optimal_fpr = fpr[optimal_idx_j]\n",
    "optimal_tpr = tpr[optimal_idx_j]\n",
    "ax2.plot(optimal_fpr, optimal_tpr, 'ro', markersize=10, label=f'Optimal Threshold: {optimal_threshold_j:.3f}')\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC Curve with Optimal Threshold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(recall, precision, 'b-', linewidth=2, label='PR Curve')\n",
    "# Mark optimal threshold\n",
    "optimal_prec = precision[optimal_idx_pr]\n",
    "optimal_rec = recall[optimal_idx_pr]\n",
    "ax3.plot(optimal_rec, optimal_prec, 'ro', markersize=10, label=f'Optimal Threshold: {optimal_threshold_pr:.3f}')\n",
    "ax3.set_xlabel('Recall')\n",
    "ax3.set_ylabel('Precision')\n",
    "ax3.set_title('Precision-Recall Curve')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Metrics comparison\n",
    "ax4 = axes[1, 1]\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "x_pos = np.arange(len(threshold_comparison_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    offset = (i - 1.5) * width\n",
    "    values = threshold_comparison_df[metric].values\n",
    "    ax4.bar(x_pos + offset, values, width, label=metric, alpha=0.7)\n",
    "\n",
    "ax4.set_xlabel('Threshold Method')\n",
    "ax4.set_ylabel('Score')\n",
    "ax4.set_title('Metrics Comparison Across Thresholds')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(threshold_comparison_df['Method'], rotation=45, ha='right')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/threshold_optimization.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Saved threshold optimization plots to ../models/threshold_optimization.png\")\n",
    "plt.show()\n",
    "\n",
    "# Store optimal threshold for use in test evaluation\n",
    "print(f\"\\nüí° Using threshold {optimal_threshold:.4f} for test set evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Test Set Evaluation (with Optimal Threshold)\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (100000,64) and (48,48) not aligned: 64 (dim 1) != 48 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Set Evaluation (with Optimal Threshold)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m test_loss, test_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy (at default 0.5): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/trainer.py:124\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, X_test, y_test)\u001b[0m\n\u001b[1;32m    121\u001b[0m y_test \u001b[38;5;241m=\u001b[39m to_device(y_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_manager)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39m_set_training(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 124\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mcompute_loss(predictions, y_test)\n\u001b[1;32m    126\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mcompute_accuracy(predictions, y_test)\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/neural_network.py:39\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m     37\u001b[0m output \u001b[38;5;241m=\u001b[39m input_data\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m---> 39\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/KhayatMiniNN/layers/lstm.py:110\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    105\u001b[0m x_t \u001b[38;5;241m=\u001b[39m input_data[:, t, :]  \u001b[38;5;66;03m# (batch_size, input_size)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Forget gate\u001b[39;00m\n\u001b[1;32m    108\u001b[0m f_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(x_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW_f\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mU_f\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_f\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    112\u001b[0m )\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Input gate\u001b[39;00m\n\u001b[1;32m    115\u001b[0m i_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigmoid(\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(x_t, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mW_i\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxp\u001b[38;5;241m.\u001b[39mdot(h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU_i\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m+\u001b[39m \n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb_i\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    119\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (100000,64) and (48,48) not aligned: 64 (dim 1) != 48 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set with optimal threshold\n",
    "print(\"=\"*60)\n",
    "print(\"Test Set Evaluation (with Optimal Threshold)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_loss, test_accuracy = trainer.evaluate(X_test, y_test.reshape(-1, 1))\n",
    "print(f\"\\nLoss: {test_loss:.4f}\")\n",
    "print(f\"Accuracy (at default 0.5): {test_accuracy:.2f}%\")\n",
    "\n",
    "# Make predictions\n",
    "y_test_pred = trainer.predict(X_test)\n",
    "y_test_pred_proba = y_test_pred.flatten()\n",
    "\n",
    "# Use optimal threshold from validation set\n",
    "try:\n",
    "    # Use optimal threshold if it was computed\n",
    "    y_test_pred_binary_optimal = (y_test_pred_proba >= optimal_threshold).astype(int)\n",
    "    print(f\"\\nUsing optimal threshold: {optimal_threshold:.4f}\")\n",
    "except NameError:\n",
    "    # Fallback to 0.5 if threshold optimization wasn't run\n",
    "    optimal_threshold = 0.5\n",
    "    y_test_pred_binary_optimal = (y_test_pred_proba >= optimal_threshold).astype(int)\n",
    "    print(f\"\\nUsing default threshold: 0.5 (run threshold optimization first)\")\n",
    "\n",
    "# Also calculate with default threshold for comparison\n",
    "y_test_pred_binary_default = (y_test_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics with optimal threshold\n",
    "test_precision_opt = precision_score(y_test, y_test_pred_binary_optimal, zero_division=0)\n",
    "test_recall_opt = recall_score(y_test, y_test_pred_binary_optimal, zero_division=0)\n",
    "test_f1_opt = f1_score(y_test, y_test_pred_binary_optimal, zero_division=0)\n",
    "test_accuracy_opt = accuracy_score(y_test, y_test_pred_binary_optimal)\n",
    "\n",
    "# Calculate metrics with default threshold\n",
    "test_precision_def = precision_score(y_test, y_test_pred_binary_default, zero_division=0)\n",
    "test_recall_def = recall_score(y_test, y_test_pred_binary_default, zero_division=0)\n",
    "test_f1_def = f1_score(y_test, y_test_pred_binary_default, zero_division=0)\n",
    "test_accuracy_def = accuracy_score(y_test, y_test_pred_binary_default)\n",
    "\n",
    "try:\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "    print(f\"AUC-ROC: {test_auc:.4f}\")\n",
    "except:\n",
    "    test_auc = None\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Performance Comparison: Default vs Optimal Threshold\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nDefault Threshold (0.5):\")\n",
    "print(f\"  Accuracy: {test_accuracy_def:.4f}\")\n",
    "print(f\"  Precision: {test_precision_def:.4f}\")\n",
    "print(f\"  Recall: {test_recall_def:.4f}\")\n",
    "print(f\"  F1-Score: {test_f1_def:.4f}\")\n",
    "\n",
    "print(f\"\\nOptimal Threshold ({optimal_threshold:.4f}):\")\n",
    "print(f\"  Accuracy: {test_accuracy_opt:.4f}\")\n",
    "print(f\"  Precision: {test_precision_opt:.4f}\")\n",
    "print(f\"  Recall: {test_recall_opt:.4f}\")\n",
    "print(f\"  F1-Score: {test_f1_opt:.4f}\")\n",
    "\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"  Accuracy: {test_accuracy_opt - test_accuracy_def:+.4f} ({((test_accuracy_opt - test_accuracy_def)/test_accuracy_def*100):+.2f}%)\")\n",
    "print(f\"  Precision: {test_precision_opt - test_precision_def:+.4f} ({((test_precision_opt - test_precision_def)/test_precision_def*100):+.2f}%)\")\n",
    "print(f\"  Recall: {test_recall_opt - test_recall_def:+.4f} ({((test_recall_opt - test_recall_def)/test_recall_def*100):+.2f}%)\")\n",
    "print(f\"  F1-Score: {test_f1_opt - test_f1_def:+.4f} ({((test_f1_opt - test_f1_def)/test_f1_def*100):+.2f}%)\")\n",
    "\n",
    "# Use optimal threshold for confusion matrix and classification report\n",
    "y_test_pred_binary = y_test_pred_binary_optimal\n",
    "test_precision = test_precision_opt\n",
    "test_recall = test_recall_opt\n",
    "test_f1 = test_f1_opt\n",
    "test_accuracy = test_accuracy_opt * 100  # Convert to percentage\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_test_pred_binary)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Confusion Matrix (with Optimal Threshold):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"                Predicted\")\n",
    "print(f\"              ‚Üì (0)   ‚Üë (1)\")\n",
    "print(f\"Actual ‚Üì (0)  {cm_test[0,0]:6d}  {cm_test[0,1]:6d}\")\n",
    "print(f\"       ‚Üë (1)  {cm_test[1,0]:6d}  {cm_test[1,1]:6d}\")\n",
    "\n",
    "print(f\"\\nClassification Report (with Optimal Threshold):\")\n",
    "print(classification_report(y_test, y_test_pred_binary, target_names=['‚Üì Lower', '‚Üë Higher']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Confusion Matrix - Validation\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ax1 \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(\u001b[43mcm_val\u001b[49m, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m, ax\u001b[38;5;241m=\u001b[39max1,\n\u001b[1;32m      7\u001b[0m             xticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m‚Üì Lower\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m‚Üë Higher\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m             yticklabels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m‚Üì Lower\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m‚Üë Higher\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix - Validation Set\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m ax1\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm_val' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Confusion Matrix - Validation\n",
    "ax1 = axes[0, 0]\n",
    "sns.heatmap(cm_val, annot=True, fmt='d', cmap='Blues', ax=ax1,\n",
    "            xticklabels=['‚Üì Lower', '‚Üë Higher'],\n",
    "            yticklabels=['‚Üì Lower', '‚Üë Higher'])\n",
    "ax1.set_title(f'Confusion Matrix - Validation Set\\nAccuracy: {val_accuracy:.2f}%')\n",
    "ax1.set_ylabel('Actual')\n",
    "ax1.set_xlabel('Predicted')\n",
    "\n",
    "# 2. Confusion Matrix - Test\n",
    "ax2 = axes[0, 1]\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=['‚Üì Lower', '‚Üë Higher'],\n",
    "            yticklabels=['‚Üì Lower', '‚Üë Higher'])\n",
    "try:\n",
    "    threshold_label = f' (threshold: {optimal_threshold:.3f})'\n",
    "except NameError:\n",
    "    threshold_label = ' (threshold: 0.5)'\n",
    "ax2.set_title(f'Confusion Matrix - Test Set\\nAccuracy: {test_accuracy:.2f}%{threshold_label}')\n",
    "ax2.set_ylabel('Actual')\n",
    "ax2.set_xlabel('Predicted')\n",
    "\n",
    "# 3. Prediction Probability Distribution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(y_val_pred_proba[y_val == 0], bins=50, alpha=0.5, label='Actual ‚Üì Lower', color='red')\n",
    "ax3.hist(y_val_pred_proba[y_val == 1], bins=50, alpha=0.5, label='Actual ‚Üë Higher', color='green')\n",
    "try:\n",
    "    ax3.axvline(x=optimal_threshold, color='red', linestyle='--', linewidth=2, label=f'Optimal Threshold: {optimal_threshold:.3f}')\n",
    "    ax3.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='Default: 0.5')\n",
    "except NameError:\n",
    "    ax3.axvline(x=0.5, color='black', linestyle='--', label='Decision Threshold: 0.5')\n",
    "ax3.set_xlabel('Predicted Probability')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Prediction Probability Distribution - Validation')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. ROC Curve (if AUC available)\n",
    "ax4 = axes[1, 1]\n",
    "if auc is not None:\n",
    "    fpr, tpr, thresholds = roc_curve(y_val, y_val_pred_proba)\n",
    "    ax4.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.3f})', linewidth=2)\n",
    "    ax4.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "    try:\n",
    "        # Mark optimal threshold on ROC curve\n",
    "        optimal_fpr_idx = np.argmin(np.abs(thresholds - optimal_threshold))\n",
    "        ax4.plot(fpr[optimal_fpr_idx], tpr[optimal_fpr_idx], 'ro', markersize=10, \n",
    "                label=f'Optimal Threshold: {optimal_threshold:.3f}')\n",
    "    except NameError:\n",
    "        pass\n",
    "    ax4.set_xlabel('False Positive Rate')\n",
    "    ax4.set_ylabel('True Positive Rate')\n",
    "    ax4.set_title('ROC Curve - Validation Set')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax4.text(0.5, 0.5, 'ROC Curve\\nNot Available', \n",
    "             ha='center', va='center', fontsize=12)\n",
    "    ax4.set_title('ROC Curve - Validation Set')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/evaluation_plots.png', dpi=150, bbox_inches='tight')\n",
    "print(\"‚úì Saved evaluation plots to ../models/evaluation_plots.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Per-Ticker Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val_pred_binary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m ticker_y_true \u001b[38;5;241m=\u001b[39m y_val[ticker_mask]\n\u001b[0;32m---> 10\u001b[0m ticker_y_pred \u001b[38;5;241m=\u001b[39m \u001b[43my_val_pred_binary\u001b[49m[ticker_mask]\n\u001b[1;32m     12\u001b[0m ticker_acc \u001b[38;5;241m=\u001b[39m accuracy_score(ticker_y_true, ticker_y_pred)\n\u001b[1;32m     13\u001b[0m ticker_precision \u001b[38;5;241m=\u001b[39m precision_score(ticker_y_true, ticker_y_pred, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_val_pred_binary' is not defined"
     ]
    }
   ],
   "source": [
    "# Analyze performance per ticker\n",
    "ticker_performance = []\n",
    "\n",
    "for ticker in np.unique(tickers_val):\n",
    "    ticker_mask = tickers_val == ticker\n",
    "    if ticker_mask.sum() == 0:\n",
    "        continue\n",
    "    \n",
    "    ticker_y_true = y_val[ticker_mask]\n",
    "    ticker_y_pred = y_val_pred_binary[ticker_mask]\n",
    "    \n",
    "    ticker_acc = accuracy_score(ticker_y_true, ticker_y_pred)\n",
    "    ticker_precision = precision_score(ticker_y_true, ticker_y_pred, zero_division=0)\n",
    "    ticker_recall = recall_score(ticker_y_true, ticker_y_pred, zero_division=0)\n",
    "    ticker_f1 = f1_score(ticker_y_true, ticker_y_pred, zero_division=0)\n",
    "    \n",
    "    ticker_performance.append({\n",
    "        'Ticker': ticker,\n",
    "        'Samples': ticker_mask.sum(),\n",
    "        'Accuracy': ticker_acc,\n",
    "        'Precision': ticker_precision,\n",
    "        'Recall': ticker_recall,\n",
    "        'F1': ticker_f1\n",
    "    })\n",
    "\n",
    "ticker_df = pd.DataFrame(ticker_performance).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Top 10 Best Performing Tickers (Validation)\")\n",
    "print(\"=\"*60)\n",
    "print(ticker_df.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Bottom 10 Worst Performing Tickers (Validation)\")\n",
    "print(\"=\"*60)\n",
    "print(ticker_df.tail(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Overall Ticker Statistics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mean Accuracy: {ticker_df['Accuracy'].mean():.4f}\")\n",
    "print(f\"Std Accuracy: {ticker_df['Accuracy'].std():.4f}\")\n",
    "print(f\"Min Accuracy: {ticker_df['Accuracy'].min():.4f}\")\n",
    "print(f\"Max Accuracy: {ticker_df['Accuracy'].max():.4f}\")\n",
    "\n",
    "# Visualize ticker performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Accuracy distribution\n",
    "axes[0].hist(ticker_df['Accuracy'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(ticker_df['Accuracy'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {ticker_df[\"Accuracy\"].mean():.3f}')\n",
    "axes[0].set_xlabel('Accuracy')\n",
    "axes[0].set_ylabel('Number of Tickers')\n",
    "axes[0].set_title('Accuracy Distribution Across Tickers')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Top/Bottom tickers\n",
    "top_n = 15\n",
    "top_tickers = ticker_df.head(top_n)\n",
    "bottom_tickers = ticker_df.tail(top_n)\n",
    "\n",
    "axes[1].barh(range(len(top_tickers)), top_tickers['Accuracy'], \n",
    "             label='Top Tickers', color='green', alpha=0.7)\n",
    "axes[1].barh(range(len(top_tickers), len(top_tickers) + len(bottom_tickers)),\n",
    "             bottom_tickers['Accuracy'], label='Bottom Tickers', color='red', alpha=0.7)\n",
    "axes[1].set_yticks(range(len(top_tickers) + len(bottom_tickers)))\n",
    "axes[1].set_yticklabels(list(top_tickers['Ticker']) + list(bottom_tickers['Ticker']))\n",
    "axes[1].set_xlabel('Accuracy')\n",
    "axes[1].set_title(f'Top {top_n} and Bottom {top_n} Tickers by Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/ticker_performance.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Saved ticker performance plots to ../models/ticker_performance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val_pred_binary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Analyze performance over time\u001b[39;00m\n\u001b[1;32m      2\u001b[0m val_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: pd\u001b[38;5;241m.\u001b[39mto_datetime(dates_val),\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m: tickers_val,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mActual\u001b[39m\u001b[38;5;124m'\u001b[39m: y_val,\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43my_val_pred_binary\u001b[49m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProbability\u001b[39m\u001b[38;5;124m'\u001b[39m: y_val_pred_proba,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect\u001b[39m\u001b[38;5;124m'\u001b[39m: (y_val \u001b[38;5;241m==\u001b[39m y_val_pred_binary)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      9\u001b[0m })\n\u001b[1;32m     11\u001b[0m val_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m val_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m     12\u001b[0m val_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m val_results_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_val_pred_binary' is not defined"
     ]
    }
   ],
   "source": [
    "# Analyze performance over time\n",
    "val_results_df = pd.DataFrame({\n",
    "    'Date': pd.to_datetime(dates_val),\n",
    "    'Ticker': tickers_val,\n",
    "    'Actual': y_val,\n",
    "    'Predicted': y_val_pred_binary,\n",
    "    'Probability': y_val_pred_proba,\n",
    "    'Correct': (y_val == y_val_pred_binary).astype(int)\n",
    "})\n",
    "\n",
    "val_results_df['Year'] = val_results_df['Date'].dt.year\n",
    "val_results_df['Month'] = val_results_df['Date'].dt.month\n",
    "val_results_df['Quarter'] = val_results_df['Date'].dt.quarter\n",
    "\n",
    "# Performance by year\n",
    "yearly_perf = val_results_df.groupby('Year').agg({\n",
    "    'Correct': ['mean', 'count']\n",
    "}).reset_index()\n",
    "yearly_perf.columns = ['Year', 'Accuracy', 'Count']\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Performance by Year (Validation)\")\n",
    "print(\"=\"*60)\n",
    "print(yearly_perf.to_string(index=False))\n",
    "\n",
    "# Performance by month\n",
    "monthly_perf = val_results_df.groupby('Month').agg({\n",
    "    'Correct': 'mean'\n",
    "}).reset_index()\n",
    "monthly_perf.columns = ['Month', 'Accuracy']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Performance by Month (Validation)\")\n",
    "print(\"=\"*60)\n",
    "print(monthly_perf.to_string(index=False))\n",
    "\n",
    "# Visualize temporal performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Yearly performance\n",
    "axes[0].bar(yearly_perf['Year'], yearly_perf['Accuracy'], alpha=0.7, edgecolor='black')\n",
    "axes[0].axhline(val_accuracy/100, color='red', linestyle='--', \n",
    "                label=f'Overall: {val_accuracy:.2f}%')\n",
    "axes[0].set_xlabel('Year')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Accuracy by Year')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Monthly performance\n",
    "axes[1].plot(monthly_perf['Month'], monthly_perf['Accuracy'], \n",
    "             marker='o', linewidth=2, markersize=8)\n",
    "axes[1].axhline(val_accuracy/100, color='red', linestyle='--', \n",
    "                label=f'Overall: {val_accuracy:.2f}%')\n",
    "axes[1].set_xlabel('Month')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Accuracy by Month')\n",
    "axes[1].set_xticks(range(1, 13))\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../models/temporal_performance.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\n‚úì Saved temporal performance plots to ../models/temporal_performance.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "Evaluation complete! Key findings:\n",
    "- Model performance on validation and test sets\n",
    "- Per-ticker analysis shows which stocks are easier/harder to predict\n",
    "- Temporal analysis shows performance over time\n",
    "- All plots saved to `../models/` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
