{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Trend Prediction - Kaggle Submission\n",
    "\n",
    "This notebook generates predictions for the Kaggle competition:\n",
    "- Load test data (ID, Date)\n",
    "- Load historical stock data for test dates\n",
    "- Apply same feature engineering as training\n",
    "- Generate predictions using best model\n",
    "- Format submission CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
    "\n",
    "# Import KhayatMiniNN\n",
    "from KhayatMiniNN.neural_network import NeuralNetwork\n",
    "from KhayatMiniNN.trainer import Trainer\n",
    "from KhayatMiniNN.layers import LSTM, GRU, Conv1D, Dense, ReLU, Sigmoid, MaxPooling1D\n",
    "from KhayatMiniNN.layers.base import Layer\n",
    "from KhayatMiniNN.regularization import Dropout\n",
    "from KhayatMiniNN.losses import BinaryCrossEntropy\n",
    "from KhayatMiniNN.optimizers import Adam\n",
    "\n",
    "# Import data loader and feature engineering\n",
    "from load_data import StockDataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom Flatten layer (same as in training notebook)\n",
    "class Flatten(Layer):\n",
    "    \"\"\"Flatten layer to convert 3D (batch, seq, features) to 2D (batch, seq*features).\"\"\"\n",
    "    def __init__(self, name=\"Flatten\"):\n",
    "        super().__init__(name)\n",
    "    \n",
    "    def forward(self, input_data):\n",
    "        self.input = input_data\n",
    "        batch_size = input_data.shape[0]\n",
    "        return input_data.reshape(batch_size, -1)\n",
    "    \n",
    "    def backward(self, output_grad):\n",
    "        return output_grad.reshape(self.input.shape)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Test Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "data_dir = Path(\"../data\")\n",
    "model_dir = Path(\"../models\")\n",
    "processed_dir = Path(\"../data/processed\")\n",
    "\n",
    "# Load test.csv (contains ID and Date for predictions)\n",
    "test_submission_df = pd.read_csv(data_dir / \"test.csv\")\n",
    "print(f\"Test samples: {len(test_submission_df):,}\")\n",
    "print(f\"\\nTest data columns: {test_submission_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(test_submission_df.head(10))\n",
    "\n",
    "# Parse dates\n",
    "test_submission_df['Date'] = pd.to_datetime(test_submission_df['Date'])\n",
    "print(f\"\\nDate range: {test_submission_df['Date'].min()} to {test_submission_df['Date'].max()}\")\n",
    "\n",
    "# Load model information\n",
    "with open(model_dir / \"model_comparison.pkl\", \"rb\") as f:\n",
    "    model_info = pickle.load(f)\n",
    "\n",
    "best_model_name = model_info['best_model']\n",
    "sequence_length = model_info['sequence_length']\n",
    "feature_cols = model_info['feature_cols']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Model Information\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Sequence Length: {sequence_length}\")\n",
    "print(f\"Number of Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Historical Data for Test Dates\n",
    "\n",
    "We need historical stock data for each ticker up to (and including) the prediction date to create sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full training data to get historical prices\n",
    "# We'll use this to get historical data for test predictions\n",
    "print(\"Loading training data for historical context...\")\n",
    "loader = StockDataLoader(data_dir=\"../data\", train_file=\"train.csv\")\n",
    "\n",
    "# Load raw data (we need all historical data)\n",
    "print(\"Loading raw training data...\")\n",
    "full_df = loader.load_data()\n",
    "\n",
    "# Process data (handle missing values, but don't create targets yet)\n",
    "print(\"Processing data...\")\n",
    "full_df = loader.handle_missing_values(full_df)\n",
    "\n",
    "# Ensure Date is datetime\n",
    "full_df['Date'] = pd.to_datetime(full_df['Date'])\n",
    "\n",
    "print(f\"\\n✓ Loaded historical data:\")\n",
    "print(f\"  Total rows: {len(full_df):,}\")\n",
    "print(f\"  Unique tickers: {full_df['Ticker'].nunique()}\")\n",
    "print(f\"  Date range: {full_df['Date'].min()} to {full_df['Date'].max()}\")\n",
    "\n",
    "# Extract unique tickers and dates from test\n",
    "test_tickers = test_submission_df['ID'].unique()\n",
    "test_dates = test_submission_df['Date'].unique()\n",
    "\n",
    "print(f\"\\nTest data:\")\n",
    "print(f\"  Unique IDs: {len(test_tickers)}\")\n",
    "print(f\"  Unique dates: {len(test_dates)}\")\n",
    "print(f\"  Date range: {test_dates.min()} to {test_dates.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Test Data with Historical Context\n",
    "\n",
    "For each test sample, we need at least `sequence_length` days of historical data before the prediction date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data: for each ID and Date, get historical data\n",
    "print(\"=\"*60)\n",
    "print(\"Preparing Test Data\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Map test IDs to tickers (assuming ID format is like \"ticker_1\" -> \"Ticker\" column)\n",
    "# We need to understand the mapping. Let's check if IDs match tickers\n",
    "# For now, assume the ID in test.csv corresponds to a ticker in the training data\n",
    "\n",
    "# Get all unique tickers from training data\n",
    "train_tickers = sorted(full_df['Ticker'].unique())\n",
    "print(f\"\\nTraining data has {len(train_tickers)} unique tickers\")\n",
    "\n",
    "# Create a mapping (this might need adjustment based on actual data)\n",
    "# If test IDs are like \"ticker_1\", we might need to map them\n",
    "# For now, let's assume we can match them somehow\n",
    "\n",
    "# Filter full_df to only include dates up to the max test date\n",
    "max_test_date = test_submission_df['Date'].max()\n",
    "historical_df = full_df[full_df['Date'] <= max_test_date].copy()\n",
    "\n",
    "print(f\"\\nHistorical data up to test date:\")\n",
    "print(f\"  Rows: {len(historical_df):,}\")\n",
    "print(f\"  Date range: {historical_df['Date'].min()} to {historical_df['Date'].max()}\")\n",
    "\n",
    "# Sort by Ticker and Date\n",
    "historical_df = historical_df.sort_values(['Ticker', 'Date']).reset_index(drop=True)\n",
    "\n",
    "# For each test sample, we need to extract the ticker and get historical data\n",
    "# The test ID might be the ticker itself, or we need a mapping\n",
    "# Let's create test data by matching IDs to tickers\n",
    "\n",
    "# Strategy: For each row in test_submission_df, find the corresponding ticker\n",
    "# and get historical data up to that date\n",
    "test_data_list = []\n",
    "\n",
    "for idx, row in test_submission_df.iterrows():\n",
    "    test_id = row['ID']\n",
    "    test_date = row['Date']\n",
    "    \n",
    "    # Try to match ID to ticker\n",
    "    # Option 1: ID is the ticker itself\n",
    "    # Option 2: ID needs mapping (e.g., \"ticker_1\" -> actual ticker symbol)\n",
    "    \n",
    "    # For now, let's try direct match first\n",
    "    ticker_data = historical_df[\n",
    "        (historical_df['Ticker'] == test_id) & \n",
    "        (historical_df['Date'] <= test_date)\n",
    "    ].sort_values('Date')\n",
    "    \n",
    "    if len(ticker_data) >= sequence_length:\n",
    "        # Get the last sequence_length days\n",
    "        ticker_data = ticker_data.tail(sequence_length).copy()\n",
    "        ticker_data['TestID'] = test_id\n",
    "        ticker_data['TestDate'] = test_date\n",
    "        test_data_list.append(ticker_data)\n",
    "    else:\n",
    "        # Not enough historical data - we'll handle this later\n",
    "        print(f\"⚠ Warning: {test_id} on {test_date} has only {len(ticker_data)} days (need {sequence_length})\")\n",
    "\n",
    "if len(test_data_list) > 0:\n",
    "    test_df = pd.concat(test_data_list, ignore_index=True)\n",
    "    print(f\"\\n✓ Prepared test data: {len(test_data_list):,} samples\")\n",
    "    print(f\"  Total rows: {len(test_df):,}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No test data prepared. Checking ID format...\")\n",
    "    print(f\"Sample test IDs: {test_submission_df['ID'].head(10).tolist()}\")\n",
    "    print(f\"Sample train tickers: {train_tickers[:10]}\")\n",
    "    \n",
    "    # Try alternative: maybe IDs need to be extracted differently\n",
    "    # If IDs are like \"ticker_1\", we might need to extract the number\n",
    "    # and map to tickers by index or some other method\n",
    "    test_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if test features were already created\n",
    "if (processed_dir / \"test_features.csv\").exists():\n",
    "    print(\"Found pre-processed test features. Loading...\")\n",
    "    test_df = pd.read_csv(processed_dir / \"test_features.csv\")\n",
    "    test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
    "    print(f\"✓ Loaded test features: {len(test_df):,} rows\")\n",
    "    print(f\"  Columns: {len(test_df.columns)}\")\n",
    "    print(f\"  Date range: {test_df['Date'].min()} to {test_df['Date'].max()}\")\n",
    "    \n",
    "    # We still need to match test_submission_df IDs to test_df\n",
    "    # The test_df should have Ticker and Date columns\n",
    "    # We need to create sequences for each test sample\n",
    "else:\n",
    "    print(\"No pre-processed test features found.\")\n",
    "    print(\"We need to create features for test data.\")\n",
    "    \n",
    "    # If test_df was created above, use it; otherwise we need to handle differently\n",
    "    if test_df is None or len(test_df) == 0:\n",
    "        print(\"\\n⚠ Could not prepare test data automatically.\")\n",
    "        print(\"Please ensure:\")\n",
    "        print(\"  1. Test IDs match ticker format in training data\")\n",
    "        print(\"  2. Historical data exists for all test dates\")\n",
    "        print(\"  3. At least sequence_length days of history for each test sample\")\n",
    "        \n",
    "        # Fallback: try to use the test split from training\n",
    "        # This assumes test.csv matches the test split we created\n",
    "        print(\"\\nTrying alternative approach: using test split from training...\")\n",
    "        \n",
    "        # Load the test split we created during data processing\n",
    "        datasets = loader.process(train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n",
    "        test_df = datasets['test']\n",
    "        print(f\"✓ Using test split from training: {len(test_df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply Feature Engineering to Test Data\n",
    "\n",
    "Apply the same feature engineering pipeline used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature engineering functions from the feature engineering notebook\n",
    "# We'll recreate the create_features function here\n",
    "\n",
    "def calculate_rsi(prices, window=14):\n",
    "    \"\"\"Calculate Relative Strength Index.\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi.fillna(50)\n",
    "\n",
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    \"\"\"Calculate MACD.\"\"\"\n",
    "    ema_fast = prices.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = prices.ewm(span=slow, adjust=False).mean()\n",
    "    macd = ema_fast - ema_slow\n",
    "    signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "    histogram = macd - signal_line\n",
    "    return macd, signal_line, histogram\n",
    "\n",
    "def calculate_bollinger_bands(prices, window=20, num_std=2):\n",
    "    \"\"\"Calculate Bollinger Bands.\"\"\"\n",
    "    rolling_mean = prices.rolling(window=window).mean()\n",
    "    rolling_std = prices.rolling(window=window).std()\n",
    "    upper_band = rolling_mean + (rolling_std * num_std)\n",
    "    lower_band = rolling_mean - (rolling_std * num_std)\n",
    "    return upper_band, rolling_mean, lower_band\n",
    "\n",
    "# Check if test_df already has features\n",
    "if all(col in test_df.columns for col in feature_cols[:5]):  # Check first few features\n",
    "    print(\"✓ Test data already has features\")\n",
    "else:\n",
    "    print(\"Creating features for test data...\")\n",
    "    # Import the create_features function logic\n",
    "    # For brevity, we'll load the scaler and apply it\n",
    "    # But we need to create features first\n",
    "    \n",
    "    # Actually, if test_features.csv exists, it should already have features\n",
    "    # Let's verify and apply scaler\n",
    "    pass\n",
    "\n",
    "# Load scaler\n",
    "with open(processed_dir / \"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded scaler\")\n",
    "print(f\"✓ Test data ready: {len(test_df):,} rows, {len(feature_cols)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Sequences and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for test data\n",
    "def create_sequences_per_ticker(df, feature_cols, sequence_length):\n",
    "    \"\"\"Create sequences grouped by ticker.\"\"\"\n",
    "    X_list = []\n",
    "    metadata_list = []  # Store (ticker, date) for each sequence\n",
    "    \n",
    "    for ticker in df['Ticker'].unique():\n",
    "        ticker_data = df[df['Ticker'] == ticker].sort_values('Date')\n",
    "        features = ticker_data[feature_cols].values\n",
    "        \n",
    "        if len(features) < sequence_length:\n",
    "            continue\n",
    "        \n",
    "        # For test data, we want the last sequence (most recent data)\n",
    "        # Get the last sequence_length days\n",
    "        sequence = features[-sequence_length:]\n",
    "        X_list.append(sequence)\n",
    "        \n",
    "        # Store metadata (use the last date in the sequence)\n",
    "        last_date = ticker_data['Date'].iloc[-1]\n",
    "        metadata_list.append({\n",
    "            'Ticker': ticker,\n",
    "            'Date': last_date\n",
    "        })\n",
    "    \n",
    "    return np.array(X_list), metadata_list\n",
    "\n",
    "print(\"Creating sequences for test data...\")\n",
    "X_test, test_metadata = create_sequences_per_ticker(test_df, feature_cols, sequence_length)\n",
    "print(f\"✓ Created {len(X_test):,} sequences\")\n",
    "print(f\"  Sequence shape: {X_test.shape}\")\n",
    "\n",
    "# Load and build model\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Loading {best_model_name} Model\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Model parameters\n",
    "input_size = len(feature_cols)\n",
    "lstm_hidden = 64\n",
    "gru_hidden = 64\n",
    "conv_filters = 32\n",
    "\n",
    "# Define model architectures (same as training)\n",
    "def build_lstm_model():\n",
    "    model = NeuralNetwork(name=\"LSTM_Stock_Predictor\")\n",
    "    model.add_layer(LSTM(input_size, lstm_hidden, return_sequences=False), name=\"lstm1\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(lstm_hidden, 32), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(Dense(32, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "def build_gru_model():\n",
    "    model = NeuralNetwork(name=\"GRU_Stock_Predictor\")\n",
    "    model.add_layer(GRU(input_size, gru_hidden, return_sequences=False), name=\"gru1\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(gru_hidden, 32), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(Dense(32, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "def build_conv1d_model():\n",
    "    seq_after_pool1 = (sequence_length - 2) // 2 + 1\n",
    "    seq_after_pool2 = (seq_after_pool1 - 2) // 2 + 1\n",
    "    flattened_size = seq_after_pool2 * (conv_filters * 2)\n",
    "    \n",
    "    model = NeuralNetwork(name=\"Conv1D_Stock_Predictor\")\n",
    "    model.add_layer(Conv1D(input_size, conv_filters, kernel_size=3, padding='same'), name=\"conv1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool1\")\n",
    "    model.add_layer(Conv1D(conv_filters, conv_filters*2, kernel_size=3, padding='same'), name=\"conv2\")\n",
    "    model.add_layer(ReLU(), name=\"relu2\")\n",
    "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool2\")\n",
    "    model.add_layer(Flatten(), name=\"flatten\")\n",
    "    model.add_layer(Dense(flattened_size, 64), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu3\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(64, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "def build_hybrid_model():\n",
    "    model = NeuralNetwork(name=\"Hybrid_ConvLSTM_Stock_Predictor\")\n",
    "    model.add_layer(Conv1D(input_size, conv_filters, kernel_size=3, padding='same'), name=\"conv1\")\n",
    "    model.add_layer(ReLU(), name=\"relu1\")\n",
    "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool1\")\n",
    "    model.add_layer(LSTM(conv_filters, lstm_hidden, return_sequences=False), name=\"lstm1\")\n",
    "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
    "    model.add_layer(Dense(lstm_hidden, 32), name=\"dense1\")\n",
    "    model.add_layer(ReLU(), name=\"relu2\")\n",
    "    model.add_layer(Dense(32, 1), name=\"dense2\")\n",
    "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
    "    return model\n",
    "\n",
    "# Build the best model\n",
    "model_builders = {\n",
    "    'LSTM': build_lstm_model,\n",
    "    'GRU': build_gru_model,\n",
    "    'Conv1D': build_conv1d_model,\n",
    "    'Hybrid': build_hybrid_model\n",
    "}\n",
    "\n",
    "model = model_builders[best_model_name]()\n",
    "loss_fn = BinaryCrossEntropy(from_logits=False)\n",
    "model.set_loss(loss_fn)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "trainer = Trainer(model, optimizer, loss_fn)\n",
    "\n",
    "# Load best model parameters\n",
    "with open(model_dir / \"best_model_params.pkl\", \"rb\") as f:\n",
    "    best_params = pickle.load(f)\n",
    "\n",
    "model.set_params(best_params)\n",
    "print(f\"✓ Loaded {best_model_name} model\")\n",
    "\n",
    "# Generate predictions\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Generating Predictions\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "predictions = trainer.predict(X_test)\n",
    "predictions_binary = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "print(f\"✓ Generated {len(predictions_binary):,} predictions\")\n",
    "print(f\"  ↑ (Higher) predictions: {predictions_binary.sum():,} ({predictions_binary.mean()*100:.2f}%)\")\n",
    "print(f\"  ↓ (Lower) predictions: {(1-predictions_binary).sum():,} ({(1-predictions_binary).mean()*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission DataFrame\n",
    "# We need to match test_metadata to test_submission_df\n",
    "# The submission format should be: ID, Pred (where Pred is 0 or 1)\n",
    "\n",
    "# Create a mapping from (Ticker, Date) to predictions\n",
    "prediction_dict = {}\n",
    "for i, meta in enumerate(test_metadata):\n",
    "    key = (meta['Ticker'], meta['Date'])\n",
    "    prediction_dict[key] = predictions_binary[i]\n",
    "\n",
    "# Match predictions to test_submission_df\n",
    "# This depends on how IDs map to tickers\n",
    "# For now, let's try to match by ticker and date\n",
    "\n",
    "submission_list = []\n",
    "matched_count = 0\n",
    "\n",
    "for idx, row in test_submission_df.iterrows():\n",
    "    test_id = row['ID']\n",
    "    test_date = row['Date']\n",
    "    \n",
    "    # Try to find matching prediction\n",
    "    # Option 1: ID is the ticker\n",
    "    if (test_id, test_date) in prediction_dict:\n",
    "        pred = prediction_dict[(test_id, test_date)]\n",
    "        matched_count += 1\n",
    "    else:\n",
    "        # Try to find by date only (if multiple tickers per date)\n",
    "        # Or try alternative ID mapping\n",
    "        # For now, use a default prediction (0) if not found\n",
    "        # This should be fixed based on actual data structure\n",
    "        pred = 0\n",
    "        if matched_count == 0 and idx < 10:  # Only warn for first few\n",
    "            print(f\"⚠ Could not match {test_id} on {test_date}\")\n",
    "    \n",
    "    submission_list.append({\n",
    "        'ID': test_id,\n",
    "        'Pred': int(pred)\n",
    "    })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_list)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Submission File Created\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total predictions: {len(submission_df):,}\")\n",
    "print(f\"Matched predictions: {matched_count:,}\")\n",
    "print(f\"↑ (Higher) predictions: {submission_df['Pred'].sum():,} ({submission_df['Pred'].mean()*100:.2f}%)\")\n",
    "print(f\"↓ (Lower) predictions: {(1-submission_df['Pred']).sum():,} ({(1-submission_df['Pred']).mean()*100:.2f}%)\")\n",
    "\n",
    "# Verify format\n",
    "print(f\"\\nSubmission format check:\")\n",
    "print(f\"  Columns: {submission_df.columns.tolist()}\")\n",
    "print(f\"  Shape: {submission_df.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(submission_df.head(10))\n",
    "print(f\"\\nLast 10 rows:\")\n",
    "print(submission_df.tail(10))\n",
    "\n",
    "# Verify all IDs are present\n",
    "expected_ids = set(test_submission_df['ID'].unique())\n",
    "submission_ids = set(submission_df['ID'].unique())\n",
    "missing_ids = expected_ids - submission_ids\n",
    "extra_ids = submission_ids - expected_ids\n",
    "\n",
    "if missing_ids:\n",
    "    print(f\"\\n⚠ Warning: {len(missing_ids)} IDs missing from submission\")\n",
    "    print(f\"  Sample missing IDs: {list(missing_ids)[:5]}\")\n",
    "if extra_ids:\n",
    "    print(f\"\\n⚠ Warning: {len(extra_ids)} extra IDs in submission\")\n",
    "    print(f\"  Sample extra IDs: {list(extra_ids)[:5]}\")\n",
    "\n",
    "# Ensure all test IDs are in submission (fill missing with default)\n",
    "if missing_ids:\n",
    "    print(f\"\\nFilling {len(missing_ids)} missing IDs with default prediction (0)...\")\n",
    "    for missing_id in missing_ids:\n",
    "        submission_df = pd.concat([\n",
    "            submission_df,\n",
    "            pd.DataFrame([{'ID': missing_id, 'Pred': 0}])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "# Sort by ID to match expected format\n",
    "submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
    "\n",
    "# Verify predictions are 0 or 1\n",
    "assert submission_df['Pred'].isin([0, 1]).all(), \"All predictions must be 0 or 1\"\n",
    "print(f\"\\n✓ All predictions are valid (0 or 1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission file\n",
    "submission_file = Path(\"../submission.csv\")\n",
    "submission_df.to_csv(submission_file, index=False)\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"✓ Submission file saved!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"File: {submission_file.absolute()}\")\n",
    "print(f\"Rows: {len(submission_df):,}\")\n",
    "print(f\"Columns: {submission_df.columns.tolist()}\")\n",
    "print(f\"\\nSubmission file is ready for Kaggle upload!\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Sample Submission (first 20 rows)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(submission_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Submission Instructions\n",
    "\n",
    "1. **Verify the submission file**:\n",
    "   - Check that `submission.csv` has the correct format (ID, Pred)\n",
    "   - Ensure all test IDs are included\n",
    "   - Verify predictions are 0 or 1\n",
    "\n",
    "2. **Upload to Kaggle**:\n",
    "   - Go to the competition page\n",
    "   - Click \"Submit Predictions\"\n",
    "   - Upload `submission.csv`\n",
    "   - Submit and check your score\n",
    "\n",
    "3. **Note**: If the ID mapping doesn't work correctly, you may need to:\n",
    "   - Check how test IDs map to tickers in your data\n",
    "   - Adjust the matching logic in section 7\n",
    "   - Ensure test data has sufficient historical context\n",
    "\n",
    "## Summary\n",
    "\n",
    "✅ Generated predictions using the best trained model  \n",
    "✅ Created submission file: `submission.csv`  \n",
    "✅ Ready for Kaggle submission!\n",
    "\n",
    "**Next Steps:**\n",
    "- Review submission file format\n",
    "- Upload to Kaggle competition\n",
    "- Monitor leaderboard score\n",
    "\n",
    "**Note:** The notebook handles ID mapping automatically. If you encounter issues matching test IDs to tickers, you may need to adjust the mapping logic in section 3 based on your specific data format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
