{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stock Trend Prediction - Kaggle Submission\n",
        "\n",
        "This notebook generates predictions for the Kaggle competition:\n",
        "- Load test data (ID, Date)\n",
        "- Load historical stock data for test dates\n",
        "- Apply same feature engineering as training\n",
        "- Generate predictions using best model\n",
        "- Format submission CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports complete\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath('__file__'))))\n",
        "\n",
        "# Import KhayatMiniNN\n",
        "from KhayatMiniNN.neural_network import NeuralNetwork\n",
        "from KhayatMiniNN.trainer import Trainer\n",
        "from KhayatMiniNN.layers import LSTM, GRU, Conv1D, Dense, ReLU, Sigmoid, MaxPooling1D\n",
        "from KhayatMiniNN.layers.base import Layer\n",
        "from KhayatMiniNN.regularization import Dropout, BatchNormalization\n",
        "from KhayatMiniNN.losses import BinaryCrossEntropy\n",
        "from KhayatMiniNN.optimizers import Adam\n",
        "\n",
        "# Import data loader and feature engineering\n",
        "from load_data import StockDataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Custom Flatten layer (same as in training notebook)\n",
        "class Flatten(Layer):\n",
        "    \"\"\"Flatten layer to convert 3D (batch, seq, features) to 2D (batch, seq*features).\"\"\"\n",
        "    def __init__(self, name=\"Flatten\"):\n",
        "        super().__init__(name)\n",
        "    \n",
        "    def forward(self, input_data):\n",
        "        self.input = input_data\n",
        "        batch_size = input_data.shape[0]\n",
        "        return input_data.reshape(batch_size, -1)\n",
        "    \n",
        "    def backward(self, output_grad):\n",
        "        return output_grad.reshape(self.input.shape)\n",
        "\n",
        "print(\"✓ Imports complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Test Data and Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test samples: 5,000\n",
            "\n",
            "Test data columns: ['ID', 'Date']\n",
            "\n",
            "First few rows:\n",
            "            ID        Date\n",
            "0     ticker_1  2024-11-04\n",
            "1    ticker_10  2024-11-04\n",
            "2   ticker_100  2024-11-04\n",
            "3  ticker_1000  2024-11-04\n",
            "4  ticker_1001  2024-11-04\n",
            "5  ticker_1002  2024-11-04\n",
            "6  ticker_1003  2024-11-04\n",
            "7  ticker_1004  2024-11-04\n",
            "8  ticker_1005  2024-11-04\n",
            "9  ticker_1006  2024-11-04\n",
            "\n",
            "Date range: 2024-11-04 00:00:00 to 2024-11-04 00:00:00\n",
            "\n",
            "============================================================\n",
            "Model Information\n",
            "============================================================\n",
            "Best Model: Hybrid\n",
            "Sequence Length: 20\n",
            "Number of Features: 71\n"
          ]
        }
      ],
      "source": [
        "# Load test data\n",
        "data_dir = Path(\"../data\")\n",
        "model_dir = Path(\"../models\")\n",
        "processed_dir = Path(\"../data/processed\")\n",
        "\n",
        "# Load test.csv (contains ID and Date for predictions)\n",
        "test_submission_df = pd.read_csv(data_dir / \"test.csv\")\n",
        "print(f\"Test samples: {len(test_submission_df):,}\")\n",
        "print(f\"\\nTest data columns: {test_submission_df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(test_submission_df.head(10))\n",
        "\n",
        "# Parse dates\n",
        "test_submission_df['Date'] = pd.to_datetime(test_submission_df['Date'])\n",
        "print(f\"\\nDate range: {test_submission_df['Date'].min()} to {test_submission_df['Date'].max()}\")\n",
        "\n",
        "# Load model information\n",
        "with open(model_dir / \"model_comparison.pkl\", \"rb\") as f:\n",
        "    model_info = pickle.load(f)\n",
        "\n",
        "best_model_name = model_info['best_model']\n",
        "sequence_length = model_info['sequence_length']\n",
        "feature_cols = model_info['feature_cols']\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Model Information\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(f\"Sequence Length: {sequence_length}\")\n",
        "print(f\"Number of Features: {len(feature_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Historical Data for Test Dates\n",
        "\n",
        "We need historical stock data for each ticker up to (and including) the prediction date to create sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading training data for historical context...\n",
            "Loading raw training data...\n",
            "Loading training data...\n",
            "Reading from: ../data/train.csv\n",
            "✓ Loaded 21,033,522 rows\n",
            "✓ Data loaded: 21,033,522 rows, 5000 unique tickers\n",
            "  Date range: 1962-01-02 00:00:00 to 2024-09-23 00:00:00\n",
            "Processing data...\n",
            "\n",
            "Handling missing values...\n",
            "✓ No missing values found\n",
            "  Removing 807,778 rows with invalid prices\n",
            "✓ Removed 807,778 rows with invalid data\n",
            "✓ Final dataset: 20,225,744 rows, 5000 unique tickers\n",
            "\n",
            "✓ Loaded historical data:\n",
            "  Total rows: 20,225,744\n",
            "  Unique tickers: 5000\n",
            "  Date range: 1962-01-02 00:00:00 to 2024-09-23 00:00:00\n",
            "\n",
            "Test data:\n",
            "  Unique IDs: 5000\n",
            "  Unique dates: 1\n",
            "  Date range: 2024-11-04 00:00:00 to 2024-11-04 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# Load full training data to get historical prices\n",
        "# We'll use this to get historical data for test predictions\n",
        "print(\"Loading training data for historical context...\")\n",
        "loader = StockDataLoader(data_dir=\"../data\", train_file=\"train.csv\")\n",
        "\n",
        "# Load raw data (we need all historical data)\n",
        "print(\"Loading raw training data...\")\n",
        "full_df = loader.load_data()\n",
        "\n",
        "# Process data (handle missing values, but don't create targets yet)\n",
        "print(\"Processing data...\")\n",
        "full_df = loader.handle_missing_values(full_df)\n",
        "\n",
        "# Ensure Date is datetime\n",
        "full_df['Date'] = pd.to_datetime(full_df['Date'])\n",
        "\n",
        "print(f\"\\n✓ Loaded historical data:\")\n",
        "print(f\"  Total rows: {len(full_df):,}\")\n",
        "print(f\"  Unique tickers: {full_df['Ticker'].nunique()}\")\n",
        "print(f\"  Date range: {full_df['Date'].min()} to {full_df['Date'].max()}\")\n",
        "\n",
        "# Extract unique tickers and dates from test\n",
        "test_tickers = test_submission_df['ID'].unique()\n",
        "test_dates = test_submission_df['Date'].unique()\n",
        "\n",
        "print(f\"\\nTest data:\")\n",
        "print(f\"  Unique IDs: {len(test_tickers)}\")\n",
        "print(f\"  Unique dates: {len(test_dates)}\")\n",
        "print(f\"  Date range: {test_dates.min()} to {test_dates.max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Prepare Test Data with Historical Context\n",
        "\n",
        "For each test sample, we need at least `sequence_length` days of historical data before the prediction date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Data Preparation - Skipped\n",
            "============================================================\n",
            "\n",
            "Data preparation will be done in the next cell where we:\n",
            "  1. Take raw historical data for test tickers\n",
            "  2. Create all features using create_features()\n",
            "  3. Scale the features using the saved scaler\n",
            "\n",
            "This ensures we use the MOST RECENT data from training (up to 2024-09-23)\n",
            "rather than stale data from a pre-computed test split.\n",
            "\n",
            "Data check:\n",
            "  Training tickers: 5,000\n",
            "  Test IDs: 5,000\n",
            "  Matching: 5,000\n"
          ]
        }
      ],
      "source": [
        "# Skip this cell - data preparation is now done in the next cell\n",
        "# which creates features from raw historical data properly\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Data Preparation - Skipped\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nData preparation will be done in the next cell where we:\")\n",
        "print(\"  1. Take raw historical data for test tickers\")\n",
        "print(\"  2. Create all features using create_features()\")\n",
        "print(\"  3. Scale the features using the saved scaler\")\n",
        "print(\"\\nThis ensures we use the MOST RECENT data from training (up to 2024-09-23)\")\n",
        "print(\"rather than stale data from a pre-computed test split.\")\n",
        "\n",
        "# Just verify we have the data we need\n",
        "train_tickers = sorted(full_df['Ticker'].unique())\n",
        "test_ids = set(test_submission_df['ID'].unique())\n",
        "matching_tickers = test_ids.intersection(set(train_tickers))\n",
        "\n",
        "print(f\"\\nData check:\")\n",
        "print(f\"  Training tickers: {len(train_tickers):,}\")\n",
        "print(f\"  Test IDs: {len(test_ids):,}\")\n",
        "print(f\"  Matching: {len(matching_tickers):,}\")\n",
        "\n",
        "if len(matching_tickers) < len(test_ids):\n",
        "    missing = test_ids - set(train_tickers)\n",
        "    print(f\"  ⚠ Missing tickers: {len(missing)}\")\n",
        "    print(f\"    Sample: {list(missing)[:5]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Creating Features from Raw Historical Data\n",
            "============================================================\n",
            "\n",
            "⚠ NOTE: Not using test_features.csv - that's the validation split!\n",
            "  We need features from the MOST RECENT historical data for each ticker.\n",
            "\n",
            "Filtering to last 250 days per ticker...\n",
            "  Filtered to test tickers: 20,225,744 rows\n",
            "  After taking last 250 days: 1,249,670 rows\n",
            "  Date range: 2017-09-25 00:00:00 to 2024-09-23 00:00:00\n",
            "\n",
            "Creating features...\n",
            "  [1/7] Basic price features...\n",
            "  [2/7] Technical indicators (RSI, MACD, Bollinger)...\n",
            "  [3/7] Volume features...\n",
            "  [4/7] Rolling statistics...\n",
            "  [5/7] Seasonality features...\n",
            "  [6/7] Long-term features (MA, volatility, trend)...\n",
            "  [7/7] Market regime & interactions...\n",
            "  Cleaning up NaN/Inf values...\n",
            "  Done!\n",
            "\n",
            "✓ Created 132 features\n",
            "  Test data shape: (1249670, 141)\n",
            "  Date range: 2017-09-25 00:00:00 to 2024-09-23 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# IMPORTANT: We need to use the RAW historical data, NOT the pre-processed test_features.csv\n",
        "# The test_features.csv is the validation test split, NOT the actual Kaggle test data!\n",
        "# The Kaggle test date is 2024-11-04, but our training data ends at 2024-09-23.\n",
        "# We use the most recent data from training to make predictions.\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Creating Features from Raw Historical Data\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n⚠ NOTE: Not using test_features.csv - that's the validation split!\")\n",
        "print(\"  We need features from the MOST RECENT historical data for each ticker.\")\n",
        "\n",
        "# Import the feature engineering function\n",
        "from feature_utils import create_features\n",
        "\n",
        "# Get the most recent data for each ticker (need enough for feature calculation)\n",
        "# Features like MA200 need 200+ days of history\n",
        "min_history_required = 250  # At least 250 days for MA200 and other features\n",
        "\n",
        "print(f\"\\nFiltering to last {min_history_required} days per ticker...\")\n",
        "test_ids = set(test_submission_df['ID'].unique())\n",
        "\n",
        "# Filter to test tickers only\n",
        "historical_df = full_df[full_df['Ticker'].isin(test_ids)].copy()\n",
        "print(f\"  Filtered to test tickers: {len(historical_df):,} rows\")\n",
        "\n",
        "# Get the last min_history_required rows per ticker for feature calculation\n",
        "historical_df = historical_df.sort_values(['Ticker', 'Date'])\n",
        "historical_df = historical_df.groupby('Ticker').tail(min_history_required).reset_index(drop=True)\n",
        "print(f\"  After taking last {min_history_required} days: {len(historical_df):,} rows\")\n",
        "print(f\"  Date range: {historical_df['Date'].min()} to {historical_df['Date'].max()}\")\n",
        "\n",
        "# Load ticker statistics from training (for ticker_mean_return_30d feature - prevents leakage)\n",
        "# This should have been saved during feature engineering, but we'll recalculate if needed\n",
        "print(\"\\nCreating features...\")\n",
        "test_df, computed_feature_cols = create_features(historical_df, verbose=True, ticker_stats=None)\n",
        "\n",
        "print(f\"\\n✓ Created {len(computed_feature_cols)} features\")\n",
        "print(f\"  Test data shape: {test_df.shape}\")\n",
        "print(f\"  Date range: {test_df['Date'].min()} to {test_df['Date'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Apply Feature Engineering to Test Data\n",
        "\n",
        "Apply the same feature engineering pipeline used during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Scaling Features\n",
            "============================================================\n",
            "✓ Loaded scaler from training\n",
            "✓ All 71 features present\n",
            "\n",
            "Cleaning inf/nan values...\n",
            "Applying scaler to test features...\n",
            "  Pre-scaling stats: min=-5533.7202, max=149865296.0000, mean=18504.4824\n",
            "  Post-scaling stats: min=-1344.1433, max=16746.5449, mean=0.3943\n",
            "\n",
            "✓ Test data scaled and ready: 1,249,670 rows, 71 features\n"
          ]
        }
      ],
      "source": [
        "# Scale the features using the same scaler from training\n",
        "print(\"=\"*60)\n",
        "print(\"Scaling Features\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load scaler\n",
        "with open(processed_dir / \"scaler.pkl\", \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "print(\"✓ Loaded scaler from training\")\n",
        "\n",
        "# Verify we have the right features\n",
        "missing_features = [f for f in feature_cols if f not in test_df.columns]\n",
        "if missing_features:\n",
        "    print(f\"⚠ Warning: {len(missing_features)} features missing from test data:\")\n",
        "    print(f\"  {missing_features[:10]}...\")\n",
        "    # Use only available features\n",
        "    available_features = [f for f in feature_cols if f in test_df.columns]\n",
        "    print(f\"  Using {len(available_features)} available features\")\n",
        "else:\n",
        "    available_features = feature_cols\n",
        "    print(f\"✓ All {len(feature_cols)} features present\")\n",
        "\n",
        "# Clean inf/nan values before scaling\n",
        "print(\"\\nCleaning inf/nan values...\")\n",
        "for col in available_features:\n",
        "    test_df[col] = test_df[col].replace([np.inf, -np.inf], np.nan)\n",
        "    test_df[col] = test_df[col].fillna(0)\n",
        "\n",
        "# Apply scaler to test features\n",
        "print(\"Applying scaler to test features...\")\n",
        "test_features = test_df[available_features].values\n",
        "\n",
        "# Check for issues before scaling\n",
        "print(f\"  Pre-scaling stats: min={test_features.min():.4f}, max={test_features.max():.4f}, mean={test_features.mean():.4f}\")\n",
        "\n",
        "# Scale\n",
        "test_features_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Check for issues after scaling\n",
        "print(f\"  Post-scaling stats: min={test_features_scaled.min():.4f}, max={test_features_scaled.max():.4f}, mean={test_features_scaled.mean():.4f}\")\n",
        "\n",
        "# Replace original features with scaled values\n",
        "test_df[available_features] = test_features_scaled\n",
        "\n",
        "# Update feature_cols to use only available features\n",
        "feature_cols = available_features\n",
        "\n",
        "print(f\"\\n✓ Test data scaled and ready: {len(test_df):,} rows, {len(feature_cols)} features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create Sequences and Generate Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating sequences for test data (optimized)...\n",
            "  Processing 5000 tickers...\n",
            "    Processed 1000/5000 tickers...\n",
            "    Processed 2000/5000 tickers...\n",
            "    Processed 3000/5000 tickers...\n",
            "    Processed 4000/5000 tickers...\n",
            "✓ Created 5,000 sequences\n",
            "  Sequence shape: (5000, 20, 71)\n",
            "\n",
            "============================================================\n",
            "Loading Hybrid Model\n",
            "============================================================\n",
            "ℹ CuPy not available, using CPU (NumPy)\n",
            "✓ Loaded Hybrid model\n",
            "\n",
            "============================================================\n",
            "Generating Predictions\n",
            "============================================================\n",
            "✓ Generated 5,000 predictions\n",
            "  ↑ (Higher) predictions: 17 (0.34%)\n",
            "  ↓ (Lower) predictions: 4,983 (99.66%)\n"
          ]
        }
      ],
      "source": [
        "# Create sequences for test data - OPTIMIZED VERSION\n",
        "def create_sequences_per_ticker_optimized(df, feature_cols, sequence_length):\n",
        "    \"\"\"Create sequences grouped by ticker - OPTIMIZED with groupby.\"\"\"\n",
        "    X_list = []\n",
        "    metadata_list = []  # Store (ticker, date) for each sequence\n",
        "    \n",
        "    # Sort once and group - much faster than filtering repeatedly\n",
        "    df_sorted = df.sort_values(['Ticker', 'Date'])\n",
        "    \n",
        "    # Pre-group the dataframe - this is the key optimization\n",
        "    ticker_groups = df_sorted.groupby('Ticker')\n",
        "    \n",
        "    # Get unique tickers\n",
        "    unique_tickers = df_sorted['Ticker'].unique()\n",
        "    print(f\"  Processing {len(unique_tickers)} tickers...\")\n",
        "    \n",
        "    for i, ticker in enumerate(unique_tickers):\n",
        "        if i % 1000 == 0 and i > 0:\n",
        "            print(f\"    Processed {i}/{len(unique_tickers)} tickers...\")\n",
        "        \n",
        "        # Get pre-grouped data (fast lookup)\n",
        "        ticker_data = ticker_groups.get_group(ticker)\n",
        "        \n",
        "        if len(ticker_data) < sequence_length:\n",
        "            continue\n",
        "        \n",
        "        # Get the last sequence_length rows\n",
        "        features = ticker_data[feature_cols].values[-sequence_length:]\n",
        "        X_list.append(features)\n",
        "        \n",
        "        # Store metadata (use the last date in the sequence)\n",
        "        last_date = ticker_data['Date'].iloc[-1]\n",
        "        metadata_list.append({\n",
        "            'Ticker': ticker,\n",
        "            'Date': last_date\n",
        "        })\n",
        "    \n",
        "    return np.array(X_list), metadata_list\n",
        "\n",
        "print(\"Creating sequences for test data (optimized)...\")\n",
        "X_test, test_metadata = create_sequences_per_ticker_optimized(test_df, feature_cols, sequence_length)\n",
        "print(f\"✓ Created {len(X_test):,} sequences\")\n",
        "print(f\"  Sequence shape: {X_test.shape}\")\n",
        "\n",
        "# Load and build model\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Loading {best_model_name} Model\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Model parameters - MUST MATCH the trained model exactly!\n",
        "# These values are inferred from best_model_params.pkl shapes:\n",
        "# conv1: W (3, 71, 32) -> input=71, filters=32\n",
        "# lstm1: W_f (32, 32), U_f (32, 32) -> input=32, hidden=32\n",
        "# dense1: W (32, 16) -> 32 -> 16\n",
        "# dense2: W (16, 1) -> 16 -> 1\n",
        "input_size = len(feature_cols)  # 71\n",
        "lstm_hidden = 32  # FIXED: was 64, but saved model uses 32\n",
        "gru_hidden = 32   # FIXED: was 64\n",
        "conv_filters = 32\n",
        "\n",
        "# Define model architectures (same as training)\n",
        "def build_lstm_model():\n",
        "    model = NeuralNetwork(name=\"LSTM_Stock_Predictor\")\n",
        "    model.add_layer(LSTM(input_size, lstm_hidden, return_sequences=False), name=\"lstm1\")\n",
        "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
        "    model.add_layer(Dense(lstm_hidden, 16), name=\"dense1\")\n",
        "    model.add_layer(ReLU(), name=\"relu1\")\n",
        "    model.add_layer(Dense(16, 1), name=\"dense2\")\n",
        "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
        "    return model\n",
        "\n",
        "def build_gru_model():\n",
        "    model = NeuralNetwork(name=\"GRU_Stock_Predictor\")\n",
        "    model.add_layer(GRU(input_size, gru_hidden, return_sequences=False), name=\"gru1\")\n",
        "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
        "    model.add_layer(Dense(gru_hidden, 16), name=\"dense1\")\n",
        "    model.add_layer(ReLU(), name=\"relu1\")\n",
        "    model.add_layer(Dense(16, 1), name=\"dense2\")\n",
        "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
        "    return model\n",
        "\n",
        "def build_conv1d_model():\n",
        "    seq_after_pool1 = (sequence_length - 2) // 2 + 1\n",
        "    seq_after_pool2 = (seq_after_pool1 - 2) // 2 + 1\n",
        "    flattened_size = seq_after_pool2 * (conv_filters * 2)\n",
        "    \n",
        "    model = NeuralNetwork(name=\"Conv1D_Stock_Predictor\")\n",
        "    model.add_layer(Conv1D(input_size, conv_filters, kernel_size=3, padding='same'), name=\"conv1\")\n",
        "    model.add_layer(ReLU(), name=\"relu1\")\n",
        "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool1\")\n",
        "    model.add_layer(Conv1D(conv_filters, conv_filters*2, kernel_size=3, padding='same'), name=\"conv2\")\n",
        "    model.add_layer(ReLU(), name=\"relu2\")\n",
        "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool2\")\n",
        "    model.add_layer(Flatten(), name=\"flatten\")\n",
        "    model.add_layer(Dense(flattened_size, 32), name=\"dense1\")\n",
        "    model.add_layer(ReLU(), name=\"relu3\")\n",
        "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
        "    model.add_layer(Dense(32, 1), name=\"dense2\")\n",
        "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
        "    return model\n",
        "\n",
        "def build_hybrid_model():\n",
        "    \"\"\"Build Hybrid model EXACTLY matching the training architecture.\n",
        "    Must match layer names exactly for parameter loading to work.\n",
        "    \"\"\"\n",
        "    model = NeuralNetwork(name=\"Hybrid_ConvLSTM_V2\")\n",
        "    # Conv1D layers for feature extraction\n",
        "    model.add_layer(Conv1D(input_size, conv_filters, kernel_size=3, padding='same'), name=\"conv1\")\n",
        "    model.add_layer(BatchNormalization(conv_filters), name=\"batchnorm1\")\n",
        "    model.add_layer(ReLU(), name=\"relu1\")\n",
        "    model.add_layer(MaxPooling1D(pool_size=2, stride=2), name=\"pool1\")\n",
        "    model.add_layer(Dropout(dropout_rate=0.3), name=\"dropout1\")\n",
        "    # LSTM for sequence modeling\n",
        "    model.add_layer(LSTM(conv_filters, lstm_hidden, return_sequences=False), name=\"lstm1\")\n",
        "    model.add_layer(BatchNormalization(lstm_hidden), name=\"batchnorm2\")\n",
        "    model.add_layer(Dropout(dropout_rate=0.6), name=\"dropout2\")\n",
        "    model.add_layer(Dense(lstm_hidden, 16), name=\"dense1\")\n",
        "    model.add_layer(ReLU(), name=\"relu2\")\n",
        "    model.add_layer(Dropout(dropout_rate=0.5), name=\"dropout3\")\n",
        "    model.add_layer(Dense(16, 1), name=\"dense2\")\n",
        "    model.add_layer(Sigmoid(), name=\"sigmoid1\")\n",
        "    return model\n",
        "\n",
        "# Build the best model\n",
        "model_builders = {\n",
        "    'LSTM': build_lstm_model,\n",
        "    'GRU': build_gru_model,\n",
        "    'Conv1D': build_conv1d_model,\n",
        "    'Hybrid': build_hybrid_model\n",
        "}\n",
        "\n",
        "model = model_builders[best_model_name]()\n",
        "loss_fn = BinaryCrossEntropy(from_logits=False)\n",
        "model.set_loss(loss_fn)\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "trainer = Trainer(model, optimizer, loss_fn)\n",
        "\n",
        "# Load best model parameters\n",
        "with open(model_dir / \"best_model_params.pkl\", \"rb\") as f:\n",
        "    best_params = pickle.load(f)\n",
        "\n",
        "model.set_params(best_params)\n",
        "print(f\"✓ Loaded {best_model_name} model\")\n",
        "\n",
        "# Generate predictions\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Generating Predictions\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "predictions = trainer.predict(X_test)\n",
        "predictions_binary = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "print(f\"✓ Generated {len(predictions_binary):,} predictions\")\n",
        "print(f\"  ↑ (Higher) predictions: {predictions_binary.sum():,} ({predictions_binary.mean()*100:.2f}%)\")\n",
        "print(f\"  ↓ (Lower) predictions: {(1-predictions_binary).sum():,} ({(1-predictions_binary).mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "DIAGNOSTIC: Analyzing Raw Predictions\n",
            "============================================================\n",
            "\n",
            "Raw predictions shape: (5000, 1)\n",
            "Raw predictions stats:\n",
            "  Min: 0.412693\n",
            "  Max: 0.510982\n",
            "  Mean: 0.463373\n",
            "  Std: 0.013778\n",
            "  Median: 0.463333\n",
            "\n",
            "Prediction distribution:\n",
            "  < 0.1: 0 (0.00%)\n",
            "  0.1-0.3: 0\n",
            "  0.3-0.5: 4,983\n",
            "  0.5-0.7: 17\n",
            "  0.7-0.9: 0\n",
            "  >= 0.9: 0\n",
            "\n",
            "Detailed distribution (percentiles):\n",
            "  1th percentile: 0.432778\n",
            "  5th percentile: 0.440803\n",
            "  10th percentile: 0.445450\n",
            "  25th percentile: 0.454085\n",
            "  50th percentile: 0.463333\n",
            "  75th percentile: 0.472317\n",
            "  90th percentile: 0.481673\n",
            "  95th percentile: 0.486641\n",
            "  99th percentile: 0.495222\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC: Input Data Statistics\n",
            "============================================================\n",
            "X_test shape: (5000, 20, 71)\n",
            "X_test stats:\n",
            "  Min: -169.1188\n",
            "  Max: 1366.0542\n",
            "  Mean: 0.4124\n",
            "  Std: 2.1168\n",
            "\n",
            "NaN values in X_test: 0\n",
            "Inf values in X_test: 0\n",
            "\n",
            "============================================================\n",
            "Trying Different Thresholds\n",
            "============================================================\n",
            "  Threshold 0.1: 5,000 predictions of 1 (100.00%)\n",
            "  Threshold 0.2: 5,000 predictions of 1 (100.00%)\n",
            "  Threshold 0.3: 5,000 predictions of 1 (100.00%)\n",
            "  Threshold 0.4: 5,000 predictions of 1 (100.00%)\n",
            "  Threshold 0.5: 17 predictions of 1 (0.34%)\n",
            "\n",
            "============================================================\n",
            "RECOMMENDATION\n",
            "============================================================\n",
            "Median prediction: 0.4633\n",
            "Your model is biased toward predicting 0.\n",
            "Suggested threshold: 0.4633 (use median to balance predictions)\n",
            "  With threshold 0.4633: 2,500 predictions of 1 (50.00%)\n"
          ]
        }
      ],
      "source": [
        "# DIAGNOSTIC: Analyze raw predictions to understand the distribution\n",
        "print(\"=\"*60)\n",
        "print(\"DIAGNOSTIC: Analyzing Raw Predictions\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check raw prediction values (before thresholding)\n",
        "print(f\"\\nRaw predictions shape: {predictions.shape}\")\n",
        "print(f\"Raw predictions stats:\")\n",
        "print(f\"  Min: {predictions.min():.6f}\")\n",
        "print(f\"  Max: {predictions.max():.6f}\")\n",
        "print(f\"  Mean: {predictions.mean():.6f}\")\n",
        "print(f\"  Std: {predictions.std():.6f}\")\n",
        "print(f\"  Median: {np.median(predictions):.6f}\")\n",
        "\n",
        "# Check distribution of predictions\n",
        "print(f\"\\nPrediction distribution:\")\n",
        "print(f\"  < 0.1: {(predictions < 0.1).sum():,} ({(predictions < 0.1).mean()*100:.2f}%)\")\n",
        "print(f\"  0.1-0.3: {((predictions >= 0.1) & (predictions < 0.3)).sum():,}\")\n",
        "print(f\"  0.3-0.5: {((predictions >= 0.3) & (predictions < 0.5)).sum():,}\")\n",
        "print(f\"  0.5-0.7: {((predictions >= 0.5) & (predictions < 0.7)).sum():,}\")\n",
        "print(f\"  0.7-0.9: {((predictions >= 0.7) & (predictions < 0.9)).sum():,}\")\n",
        "print(f\"  >= 0.9: {(predictions >= 0.9).sum():,}\")\n",
        "\n",
        "# Show histogram-like distribution\n",
        "print(f\"\\nDetailed distribution (percentiles):\")\n",
        "for p in [1, 5, 10, 25, 50, 75, 90, 95, 99]:\n",
        "    print(f\"  {p}th percentile: {np.percentile(predictions, p):.6f}\")\n",
        "\n",
        "# Check input data statistics\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"DIAGNOSTIC: Input Data Statistics\")\n",
        "print(\"=\"*60)\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"X_test stats:\")\n",
        "print(f\"  Min: {X_test.min():.4f}\")\n",
        "print(f\"  Max: {X_test.max():.4f}\")\n",
        "print(f\"  Mean: {X_test.mean():.4f}\")\n",
        "print(f\"  Std: {X_test.std():.4f}\")\n",
        "\n",
        "# Check for NaN/Inf values\n",
        "print(f\"\\nNaN values in X_test: {np.isnan(X_test).sum()}\")\n",
        "print(f\"Inf values in X_test: {np.isinf(X_test).sum()}\")\n",
        "\n",
        "# Try different thresholds\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Trying Different Thresholds\")\n",
        "print(\"=\"*60)\n",
        "for threshold in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
        "    pred_binary = (predictions > threshold).astype(int).flatten()\n",
        "    print(f\"  Threshold {threshold}: {pred_binary.sum():,} predictions of 1 ({pred_binary.mean()*100:.2f}%)\")\n",
        "\n",
        "# RECOMMENDATION based on median\n",
        "median_pred = np.median(predictions)\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"RECOMMENDATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Median prediction: {median_pred:.4f}\")\n",
        "if median_pred < 0.5:\n",
        "    suggested_threshold = median_pred\n",
        "    print(f\"Your model is biased toward predicting 0.\")\n",
        "    print(f\"Suggested threshold: {suggested_threshold:.4f} (use median to balance predictions)\")\n",
        "    balanced_preds = (predictions > suggested_threshold).astype(int).flatten()\n",
        "    print(f\"  With threshold {suggested_threshold:.4f}: {balanced_preds.sum():,} predictions of 1 ({balanced_preds.mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using custom threshold: 0.4633\n",
            "\n",
            "Prediction distribution with threshold 0.4633:\n",
            "  ↑ (Higher/1): 2,500 (50.00%)\n",
            "  ↓ (Lower/0): 2,500 (50.00%)\n"
          ]
        }
      ],
      "source": [
        "# OPTIONAL: Use a different threshold to get more balanced predictions\n",
        "# Change USE_CUSTOM_THRESHOLD to True and adjust CUSTOM_THRESHOLD as needed\n",
        "\n",
        "USE_CUSTOM_THRESHOLD = True  # Set to True to use custom threshold\n",
        "CUSTOM_THRESHOLD = np.median(predictions)  # Use median for balanced predictions\n",
        "\n",
        "if USE_CUSTOM_THRESHOLD:\n",
        "    print(f\"Using custom threshold: {CUSTOM_THRESHOLD:.4f}\")\n",
        "    predictions_binary = (predictions > CUSTOM_THRESHOLD).astype(int).flatten()\n",
        "else:\n",
        "    print(\"Using default threshold: 0.5\")\n",
        "    predictions_binary = (predictions > 0.5).astype(int).flatten()\n",
        "\n",
        "print(f\"\\nPrediction distribution with threshold {CUSTOM_THRESHOLD if USE_CUSTOM_THRESHOLD else 0.5:.4f}:\")\n",
        "print(f\"  ↑ (Higher/1): {predictions_binary.sum():,} ({predictions_binary.mean()*100:.2f}%)\")\n",
        "print(f\"  ↓ (Lower/0): {(1-predictions_binary).sum():,} ({(1-predictions_binary).mean()*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating submission DataFrame (optimized)...\n",
            "\n",
            "============================================================\n",
            "Submission File Created\n",
            "============================================================\n",
            "Total predictions: 5,000\n",
            "Matched predictions: 5,000\n",
            "↑ (Higher) predictions: 2,500 (50.00%)\n",
            "↓ (Lower) predictions: 2,500 (50.00%)\n",
            "\n",
            "Submission format check:\n",
            "  Columns: ['ID', 'Pred']\n",
            "  Shape: (5000, 2)\n",
            "\n",
            "First 10 rows:\n",
            "            ID  Pred\n",
            "0     ticker_1     0\n",
            "1    ticker_10     0\n",
            "2   ticker_100     0\n",
            "3  ticker_1000     1\n",
            "4  ticker_1001     1\n",
            "5  ticker_1002     1\n",
            "6  ticker_1003     0\n",
            "7  ticker_1004     1\n",
            "8  ticker_1005     0\n",
            "9  ticker_1006     0\n",
            "\n",
            "Last 10 rows:\n",
            "              ID  Pred\n",
            "4990  ticker_990     1\n",
            "4991  ticker_991     0\n",
            "4992  ticker_992     1\n",
            "4993  ticker_993     1\n",
            "4994  ticker_994     1\n",
            "4995  ticker_995     0\n",
            "4996  ticker_996     1\n",
            "4997  ticker_997     0\n",
            "4998  ticker_998     1\n",
            "4999  ticker_999     1\n",
            "\n",
            "✓ All predictions are valid (0 or 1)\n"
          ]
        }
      ],
      "source": [
        "# Create submission DataFrame - OPTIMIZED VERSION\n",
        "# We need to match test_metadata to test_submission_df\n",
        "# The submission format should be: ID, Pred (where Pred is 0 or 1)\n",
        "\n",
        "print(\"Creating submission DataFrame (optimized)...\")\n",
        "\n",
        "# Create a DataFrame from predictions metadata - VECTORIZED approach\n",
        "predictions_df = pd.DataFrame(test_metadata)\n",
        "predictions_df['Pred'] = predictions_binary\n",
        "\n",
        "# Since test IDs match tickers directly, we can use a simple merge/map\n",
        "# Create a mapping from Ticker to prediction\n",
        "ticker_to_pred = dict(zip(predictions_df['Ticker'], predictions_df['Pred']))\n",
        "\n",
        "# Map predictions to test submission IDs - VECTORIZED (no loops!)\n",
        "submission_df = test_submission_df[['ID']].copy()\n",
        "submission_df['Pred'] = submission_df['ID'].map(ticker_to_pred)\n",
        "\n",
        "# Count matches\n",
        "matched_count = submission_df['Pred'].notna().sum()\n",
        "unmatched_ids = submission_df[submission_df['Pred'].isna()]['ID'].tolist()\n",
        "\n",
        "# Fill missing predictions with default (0)\n",
        "if len(unmatched_ids) > 0:\n",
        "    print(f\"⚠ Warning: {len(unmatched_ids)} IDs not matched, filling with default (0)\")\n",
        "    if len(unmatched_ids) <= 10:\n",
        "        print(f\"  Unmatched IDs: {unmatched_ids}\")\n",
        "    submission_df['Pred'] = submission_df['Pred'].fillna(0)\n",
        "\n",
        "# Convert to int\n",
        "submission_df['Pred'] = submission_df['Pred'].astype(int)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Submission File Created\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total predictions: {len(submission_df):,}\")\n",
        "print(f\"Matched predictions: {matched_count:,}\")\n",
        "print(f\"↑ (Higher) predictions: {submission_df['Pred'].sum():,} ({submission_df['Pred'].mean()*100:.2f}%)\")\n",
        "print(f\"↓ (Lower) predictions: {(1-submission_df['Pred']).sum():,} ({(1-submission_df['Pred']).mean()*100:.2f}%)\")\n",
        "\n",
        "# Verify format\n",
        "print(f\"\\nSubmission format check:\")\n",
        "print(f\"  Columns: {submission_df.columns.tolist()}\")\n",
        "print(f\"  Shape: {submission_df.shape}\")\n",
        "print(f\"\\nFirst 10 rows:\")\n",
        "print(submission_df.head(10))\n",
        "print(f\"\\nLast 10 rows:\")\n",
        "print(submission_df.tail(10))\n",
        "\n",
        "# Verify all IDs are present\n",
        "expected_ids = set(test_submission_df['ID'].unique())\n",
        "submission_ids = set(submission_df['ID'].unique())\n",
        "missing_ids = expected_ids - submission_ids\n",
        "\n",
        "if missing_ids:\n",
        "    print(f\"\\n⚠ Warning: {len(missing_ids)} IDs missing from submission\")\n",
        "    print(f\"  Sample missing IDs: {list(missing_ids)[:5]}\")\n",
        "    # Add missing IDs with default prediction\n",
        "    missing_df = pd.DataFrame({'ID': list(missing_ids), 'Pred': 0})\n",
        "    submission_df = pd.concat([submission_df, missing_df], ignore_index=True)\n",
        "\n",
        "# Sort by ID to match expected format\n",
        "submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
        "\n",
        "# Verify predictions are 0 or 1\n",
        "assert submission_df['Pred'].isin([0, 1]).all(), \"All predictions must be 0 or 1\"\n",
        "print(f\"\\n✓ All predictions are valid (0 or 1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "✓ Submission file saved!\n",
            "============================================================\n",
            "File: /Users/mahmoud/Documents/University/Fourth_year/NN/Sem-project/stock-predictor/notebooks/../submission.csv\n",
            "Rows: 5,000\n",
            "Columns: ['ID', 'Pred']\n",
            "\n",
            "Submission file is ready for Kaggle upload!\n",
            "\n",
            "============================================================\n",
            "Sample Submission (first 20 rows)\n",
            "============================================================\n",
            "         ID  Pred\n",
            "   ticker_1     0\n",
            "  ticker_10     0\n",
            " ticker_100     0\n",
            "ticker_1000     1\n",
            "ticker_1001     1\n",
            "ticker_1002     1\n",
            "ticker_1003     0\n",
            "ticker_1004     1\n",
            "ticker_1005     0\n",
            "ticker_1006     0\n",
            "ticker_1007     0\n",
            "ticker_1008     0\n",
            "ticker_1009     1\n",
            " ticker_101     0\n",
            "ticker_1010     1\n",
            "ticker_1011     1\n",
            "ticker_1012     0\n",
            "ticker_1013     0\n",
            "ticker_1014     0\n",
            "ticker_1015     0\n"
          ]
        }
      ],
      "source": [
        "# Save submission file\n",
        "submission_file = Path(\"../submission.csv\")\n",
        "submission_df.to_csv(submission_file, index=False)\n",
        "\n",
        "print(f\"{'='*60}\")\n",
        "print(\"✓ Submission file saved!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"File: {submission_file.absolute()}\")\n",
        "print(f\"Rows: {len(submission_df):,}\")\n",
        "print(f\"Columns: {submission_df.columns.tolist()}\")\n",
        "print(f\"\\nSubmission file is ready for Kaggle upload!\")\n",
        "\n",
        "# Display sample\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Sample Submission (first 20 rows)\")\n",
        "print(f\"{'='*60}\")\n",
        "print(submission_df.head(20).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Submission Instructions\n",
        "\n",
        "1. **Verify the submission file**:\n",
        "   - Check that `submission.csv` has the correct format (ID, Pred)\n",
        "   - Ensure all test IDs are included\n",
        "   - Verify predictions are 0 or 1\n",
        "\n",
        "2. **Upload to Kaggle**:\n",
        "   - Go to the competition page\n",
        "   - Click \"Submit Predictions\"\n",
        "   - Upload `submission.csv`\n",
        "   - Submit and check your score\n",
        "\n",
        "3. **Note**: If the ID mapping doesn't work correctly, you may need to:\n",
        "   - Check how test IDs map to tickers in your data\n",
        "   - Adjust the matching logic in section 7\n",
        "   - Ensure test data has sufficient historical context\n",
        "\n",
        "## Summary\n",
        "\n",
        "✅ Generated predictions using the best trained model  \n",
        "✅ Created submission file: `submission.csv`  \n",
        "✅ Ready for Kaggle submission!\n",
        "\n",
        "**Next Steps:**\n",
        "- Review submission file format\n",
        "- Upload to Kaggle competition\n",
        "- Monitor leaderboard score\n",
        "\n",
        "**Note:** The notebook handles ID mapping automatically. If you encounter issues matching test IDs to tickers, you may need to adjust the mapping logic in section 3 based on your specific data format."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
